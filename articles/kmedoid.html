<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="description" content="kmed">
<title>kmed: Distance-Based K-Medoids • kmed</title>
<script src="../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="../deps/bootstrap-5.1.3/bootstrap.min.css" rel="stylesheet">
<script src="../deps/bootstrap-5.1.3/bootstrap.bundle.min.js"></script><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous">
<!-- bootstrap-toc --><script src="https://cdn.rawgit.com/afeld/bootstrap-toc/v1.0.1/dist/bootstrap-toc.min.js"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><!-- search --><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- pkgdown --><script src="../pkgdown.js"></script><meta property="og:title" content="kmed: Distance-Based K-Medoids">
<meta property="og:description" content="kmed">
<!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>
    

    <nav class="navbar fixed-top navbar-dark navbar-expand-lg bg-primary"><div class="container">
    
    <a class="navbar-brand me-2" href="../index.html">kmed</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="">0.4.2</small>

    
    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto">
<li class="nav-item">
  <a class="nav-link" href="../reference/index.html">Reference</a>
</li>
<li class="active nav-item dropdown">
  <a href="#" class="nav-link dropdown-toggle" data-bs-toggle="dropdown" role="button" aria-expanded="false" aria-haspopup="true" id="dropdown-articles">Articles</a>
  <div class="dropdown-menu" aria-labelledby="dropdown-articles">
    <a class="dropdown-item" href="../articles/kmedoid.html">kmed: Distance-Based K-Medoids</a>
  </div>
</li>
<li class="nav-item">
  <a class="nav-link" href="../news/index.html">Changelog</a>
</li>
      </ul>
<form class="form-inline my-2 my-lg-0" role="search">
        <input type="search" class="form-control me-sm-2" aria-label="Toggle navigation" name="search-input" data-search-index="../search.json" id="search-input" placeholder="Search for" autocomplete="off">
</form>

      <ul class="navbar-nav"></ul>
</div>

    
  </div>
</nav><div class="container template-article">




<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">
      <img src="" class="logo" alt=""><h1>kmed: Distance-Based K-Medoids</h1>
                        <h4 data-toc-skip class="author">Weksi
Budiaji</h4>
            
            <h4 data-toc-skip class="date">2022-12-14</h4>
      
      
      <div class="d-none name"><code>kmedoid.Rmd</code></div>
    </div>

    
        <div class="abstract">
      <p class="abstract">Abstract</p>
      <p>The <a href="https://cran.r-project.org/package=kmed" class="external-link"><strong>kmed</strong></a>
      vignette consists of four sequantial parts of distance-based
      (k-medoids) cluster analysis. The first part is defining the
      distance. It has numerical, binary, categorical, and mixed
      distances. The next part is applying a clustering algorithm in the
      pre-defined distance. There are five k-medoids presented, namely
      the simple and fast k-medoids, k-medoids, ranked k-medoids,
      increasing number of clusters in k-medoids, and simple k-medoids.
      After the clustering result is obtained, a validation step is
      required. The cluster validation applies internal and relative
      criteria. The last part is visualizing the cluster result in a
      biplot or marked barplot.</p>
    </div>
    
<div class="section level3">
<h3 id="intro">1. Introduction<a class="anchor" aria-label="anchor" href="#intro"></a>
</h3>
<p>The <a href="https://cran.r-project.org/package=kmed" class="external-link"><strong>kmed</strong></a>
package is designed to analyse k-medoids based clustering. The features
include:</p>
<ul>
<li>distance computation:
<ul>
<li>numerical variables:
<ul>
<li><a href="#mrw">Manhattan weighted by range</a></li>
<li><a href="#ser">squared Euclidean weighted by range</a></li>
<li><a href="#ser.2">squared Euclidean weighted by squared
range</a></li>
<li><a href="#sev">squared Euclidean weighted by variance</a></li>
<li><a href="#se">unweighted squared Euclidean</a></li>
</ul>
</li>
<li>binary or categorical variables:
<ul>
<li><a href="#sm">simple matching</a></li>
<li><a href="#cooc">co-occurrence</a></li>
</ul>
</li>
<li>mixed variables:
<ul>
<li><a href="#gower">Gower</a></li>
<li><a href="#wishart">Wishart</a></li>
<li><a href="#podani">Podani</a></li>
<li><a href="#huang">Huang</a></li>
<li><a href="#harikumar">Harikumar and PV</a></li>
<li><a href="#ahmad">Ahmad and Dey</a></li>
</ul>
</li>
</ul>
</li>
<li>k-medoids algorithms:
<ul>
<li><a href="#sfkm">Simple and fast k-medoids</a></li>
<li><a href="#km">K-medoids</a></li>
<li><a href="#rkm">Rank k-medoids</a></li>
<li><a href="#inckm">Increasing number of clusters k-medoids</a></li>
<li><a href="#skm">simple k-medoids</a></li>
</ul>
</li>
<li>cluster validations:
<ul>
<li>internal criteria:
<ul>
<li><a href="#sil">Silhouette</a></li>
<li><a href="#csv">Centroid-based shadow value</a></li>
<li><a href="#msv">Medoid-based shadow value</a></li>
</ul>
</li>
<li><a href="#boot">relative criteria (bootstrap)</a></li>
</ul>
</li>
<li>Cluster visualizations:
<ul>
<li><a href="#biplot">pca biplot</a></li>
<li><a href="#barplotnum">marked barplot</a></li>
</ul>
</li>
</ul>
</div>
<div class="section level3">
<h3 id="distance-computation">2. Distance Computation<a class="anchor" aria-label="anchor" href="#distance-computation"></a>
</h3>
<div class="section level4">
<h4 id="a--numerical-variables-distnumeric">2.A. Numerical variables (<code>distNumeric</code>)<a class="anchor" aria-label="anchor" href="#a--numerical-variables-distnumeric"></a>
</h4>
<p>The <code>distNumeric</code> function can be applied to calculate
numerical distances. There are four distance options, namely Manhattan
weighted by range (<code>mrw</code>), squared Euclidean weighted by
range (<code>ser</code>), squared Euclidean weighted by squared range
(<code>ser.2</code>), squared Euclidean weighted by variance
(<code>sev</code>), and unweighted squared Euclidean (<code>se</code>).
The <code>distNumeric</code> function provides <code>method</code> in
which the desired distance method can be selected. The default
<code>method</code> is <code>mrw</code>.</p>
<p>The distance computation in a numerical variable data set is
performed in the iris data set. An example of manual calculation of the
numerical distances is applied for the first and second objects only to
introduce what the <code>distNumeric</code> function does.</p>
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va">kmed</span><span class="op">)</span></span>
<span><span class="va">iris</span><span class="op">[</span><span class="fl">1</span><span class="op">:</span><span class="fl">3</span>,<span class="op">]</span></span></code></pre></div>
<pre><code><span><span class="co">##   Sepal.Length Sepal.Width Petal.Length Petal.Width Species</span></span>
<span><span class="co">## 1          5.1         3.5          1.4         0.2  setosa</span></span>
<span><span class="co">## 2          4.9         3.0          1.4         0.2  setosa</span></span>
<span><span class="co">## 3          4.7         3.2          1.3         0.2  setosa</span></span></code></pre>
<div class="section level5">
<h5 id="mrw">2.A.1. Manhattan weighted by range
(<code>method = "mrw"</code>)<a class="anchor" aria-label="anchor" href="#mrw"></a>
</h5>
<p>By applying the <code>distNumeric</code> function with
<code>method = "mrw"</code>, the distance among objects in the iris data
set can be obtained.</p>
<div class="sourceCode" id="cb3"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">num</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html" class="external-link">as.matrix</a></span><span class="op">(</span><span class="va">iris</span><span class="op">[</span>,<span class="fl">1</span><span class="op">:</span><span class="fl">4</span><span class="op">]</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/colnames.html" class="external-link">rownames</a></span><span class="op">(</span><span class="va">num</span><span class="op">)</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/colnames.html" class="external-link">rownames</a></span><span class="op">(</span><span class="va">iris</span><span class="op">)</span></span>
<span><span class="co">#calculate the Manhattan weighted by range distance of all iris objects</span></span>
<span><span class="va">mrwdist</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/distNumeric.html">distNumeric</a></span><span class="op">(</span><span class="va">num</span>, <span class="va">num</span><span class="op">)</span></span>
<span><span class="co">#show the distance among objects 1 to 3</span></span>
<span><span class="va">mrwdist</span><span class="op">[</span><span class="fl">1</span><span class="op">:</span><span class="fl">3</span>,<span class="fl">1</span><span class="op">:</span><span class="fl">3</span><span class="op">]</span></span></code></pre></div>
<pre><code><span><span class="co">##           1         2         3</span></span>
<span><span class="co">## 1 0.0000000 0.2638889 0.2530603</span></span>
<span><span class="co">## 2 0.2638889 0.0000000 0.1558380</span></span>
<span><span class="co">## 3 0.2530603 0.1558380 0.0000000</span></span></code></pre>
<p>The Manhattan weighted by range distance between objects 1 and 2 is
<code>0.2638889</code>. To calculate this distance, the range of each
variable is computed.</p>
<div class="sourceCode" id="cb5"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co">#extract the range of each variable</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/apply.html" class="external-link">apply</a></span><span class="op">(</span><span class="va">num</span>, <span class="fl">2</span>, <span class="kw">function</span><span class="op">(</span><span class="va">x</span><span class="op">)</span> <span class="fu"><a href="https://rdrr.io/r/base/Extremes.html" class="external-link">max</a></span><span class="op">(</span><span class="va">x</span><span class="op">)</span><span class="op">-</span><span class="fu"><a href="https://rdrr.io/r/base/Extremes.html" class="external-link">min</a></span><span class="op">(</span><span class="va">x</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">## Sepal.Length  Sepal.Width Petal.Length  Petal.Width </span></span>
<span><span class="co">##          3.6          2.4          5.9          2.4</span></span></code></pre>
<p>Then, the distance between objects 1 and 2 is</p>
<div class="sourceCode" id="cb7"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co">#the distance between objects 1 and 2</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/MathFun.html" class="external-link">abs</a></span><span class="op">(</span><span class="fl">5.1</span><span class="op">-</span><span class="fl">4.9</span><span class="op">)</span><span class="op">/</span><span class="fl">3.6</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/base/MathFun.html" class="external-link">abs</a></span><span class="op">(</span><span class="fl">3.5</span> <span class="op">-</span> <span class="fl">3.0</span><span class="op">)</span><span class="op">/</span><span class="fl">2.4</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/base/MathFun.html" class="external-link">abs</a></span><span class="op">(</span><span class="fl">1.4</span><span class="op">-</span><span class="fl">1.4</span><span class="op">)</span><span class="op">/</span><span class="fl">5.9</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/base/MathFun.html" class="external-link">abs</a></span><span class="op">(</span><span class="fl">0.2</span><span class="op">-</span><span class="fl">0.2</span><span class="op">)</span><span class="op">/</span><span class="fl">2.4</span></span></code></pre></div>
<pre><code><span><span class="co">## [1] 0.2638889</span></span></code></pre>
<p>which is based on the data</p>
<pre><code><span><span class="co">##   Sepal.Length Sepal.Width Petal.Length Petal.Width</span></span>
<span><span class="co">## 1          5.1         3.5          1.4         0.2</span></span>
<span><span class="co">## 2          4.9         3.0          1.4         0.2</span></span></code></pre>
<p><a href="#intro">(Back to Intoduction)</a></p>
</div>
<div class="section level5">
<h5 id="ser">2.A.2. squared Euclidean weighted by range
(<code>method = "ser"</code>)<a class="anchor" aria-label="anchor" href="#ser"></a>
</h5>
<div class="sourceCode" id="cb10"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co">#calculate the squared Euclidean weighthed by range distance of all iris objects</span></span>
<span><span class="va">serdist</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/distNumeric.html">distNumeric</a></span><span class="op">(</span><span class="va">num</span>, <span class="va">num</span>, method <span class="op">=</span> <span class="st">"ser"</span><span class="op">)</span></span>
<span><span class="co">#show the distance among objects 1 to 3</span></span>
<span><span class="va">serdist</span><span class="op">[</span><span class="fl">1</span><span class="op">:</span><span class="fl">3</span>,<span class="fl">1</span><span class="op">:</span><span class="fl">3</span><span class="op">]</span></span></code></pre></div>
<pre><code><span><span class="co">##            1          2          3</span></span>
<span><span class="co">## 1 0.00000000 0.11527778 0.08363936</span></span>
<span><span class="co">## 2 0.11527778 0.00000000 0.02947269</span></span>
<span><span class="co">## 3 0.08363936 0.02947269 0.00000000</span></span></code></pre>
<p>The squared Euclidean weighted by range distance between objects 1
and 2 is <code>0.11527778</code>. It is obtained by</p>
<div class="sourceCode" id="cb12"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co">#the distance between objects 1 and 2</span></span>
<span><span class="op">(</span><span class="fl">5.1</span><span class="op">-</span><span class="fl">4.9</span><span class="op">)</span><span class="op">^</span><span class="fl">2</span><span class="op">/</span><span class="fl">3.6</span> <span class="op">+</span> <span class="op">(</span><span class="fl">3.5</span> <span class="op">-</span> <span class="fl">3.0</span><span class="op">)</span><span class="op">^</span><span class="fl">2</span><span class="op">/</span><span class="fl">2.4</span> <span class="op">+</span> <span class="op">(</span><span class="fl">1.4</span><span class="op">-</span><span class="fl">1.4</span><span class="op">)</span><span class="op">^</span><span class="fl">2</span><span class="op">/</span><span class="fl">5.9</span> <span class="op">+</span> <span class="op">(</span><span class="fl">0.2</span><span class="op">-</span><span class="fl">0.2</span><span class="op">)</span><span class="op">^</span><span class="fl">2</span><span class="op">/</span><span class="fl">2.4</span></span></code></pre></div>
<pre><code><span><span class="co">## [1] 0.1152778</span></span></code></pre>
<p><a href="#intro">(Back to Intoduction)</a></p>
</div>
<div class="section level5">
<h5 id="ser-2">2.A.3. squared Euclidean weighted by squared range
(<code>method = "ser.2"</code>)<a class="anchor" aria-label="anchor" href="#ser-2"></a>
</h5>
<div class="sourceCode" id="cb14"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co">#calculate the squared Euclidean weighthed by squared range distance of </span></span>
<span><span class="co">#all iris objects</span></span>
<span><span class="va">ser.2dist</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/distNumeric.html">distNumeric</a></span><span class="op">(</span><span class="va">num</span>, <span class="va">num</span>, method <span class="op">=</span> <span class="st">"ser.2"</span><span class="op">)</span></span>
<span><span class="co">#show the distance among objects 1 to 3</span></span>
<span><span class="va">ser.2dist</span><span class="op">[</span><span class="fl">1</span><span class="op">:</span><span class="fl">3</span>,<span class="fl">1</span><span class="op">:</span><span class="fl">3</span><span class="op">]</span></span></code></pre></div>
<pre><code><span><span class="co">##            1          2          3</span></span>
<span><span class="co">## 1 0.00000000 0.04648920 0.02825795</span></span>
<span><span class="co">## 2 0.04648920 0.00000000 0.01031814</span></span>
<span><span class="co">## 3 0.02825795 0.01031814 0.00000000</span></span></code></pre>
<p>The squared Euclidean weighted by squared range distance between
objects 1 and 2 is <code>0.04648920</code> that is computed by</p>
<div class="sourceCode" id="cb16"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="op">(</span><span class="fl">5.1</span><span class="op">-</span><span class="fl">4.9</span><span class="op">)</span><span class="op">^</span><span class="fl">2</span><span class="op">/</span><span class="fl">3.6</span><span class="op">^</span><span class="fl">2</span> <span class="op">+</span> <span class="op">(</span><span class="fl">3.5</span> <span class="op">-</span> <span class="fl">3.0</span><span class="op">)</span><span class="op">^</span><span class="fl">2</span><span class="op">/</span><span class="fl">2.4</span><span class="op">^</span><span class="fl">2</span> <span class="op">+</span> <span class="op">(</span><span class="fl">1.4</span><span class="op">-</span><span class="fl">1.4</span><span class="op">)</span><span class="op">^</span><span class="fl">2</span><span class="op">/</span><span class="fl">5.9</span><span class="op">^</span><span class="fl">2</span> <span class="op">+</span> <span class="op">(</span><span class="fl">0.2</span><span class="op">-</span><span class="fl">0.2</span><span class="op">)</span><span class="op">^</span><span class="fl">2</span><span class="op">/</span><span class="fl">2.4</span><span class="op">^</span><span class="fl">2</span></span></code></pre></div>
<pre><code><span><span class="co">## [1] 0.0464892</span></span></code></pre>
<p>where the data are</p>
<pre><code><span><span class="co">##   Sepal.Length Sepal.Width Petal.Length Petal.Width</span></span>
<span><span class="co">## 1          5.1         3.5          1.4         0.2</span></span>
<span><span class="co">## 2          4.9         3.0          1.4         0.2</span></span></code></pre>
<p><a href="#intro">(Back to Intoduction)</a></p>
</div>
<div class="section level5">
<h5 id="a-4--squared-euclidean-weighted-by-variance-method-sev">2.A.4. squared Euclidean weighted by variance
(<code>method = "sev"</code>)<a class="anchor" aria-label="anchor" href="#a-4--squared-euclidean-weighted-by-variance-method-sev"></a>
</h5>
<div class="sourceCode" id="cb19"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co">#calculate the squared Euclidean weighthed by variance distance of </span></span>
<span><span class="co">#all iris objects</span></span>
<span><span class="va">sevdist</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/distNumeric.html">distNumeric</a></span><span class="op">(</span><span class="va">num</span>, <span class="va">num</span>, method <span class="op">=</span> <span class="st">"sev"</span><span class="op">)</span></span>
<span><span class="co">#show the distance among objects 1 to 3</span></span>
<span><span class="va">sevdist</span><span class="op">[</span><span class="fl">1</span><span class="op">:</span><span class="fl">3</span>,<span class="fl">1</span><span class="op">:</span><span class="fl">3</span><span class="op">]</span></span></code></pre></div>
<pre><code><span><span class="co">##           1         2         3</span></span>
<span><span class="co">## 1 0.0000000 1.3742671 0.7102849</span></span>
<span><span class="co">## 2 1.3742671 0.0000000 0.2720932</span></span>
<span><span class="co">## 3 0.7102849 0.2720932 0.0000000</span></span></code></pre>
<p>The squared Euclidean weighted by variance distance between objects 1
and 2 is <code>1.3742671</code>. To compute this distance, the variance
of each variable is calculated.</p>
<div class="sourceCode" id="cb21"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co">#calculate the range of each variable</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/apply.html" class="external-link">apply</a></span><span class="op">(</span><span class="va">num</span><span class="op">[</span>,<span class="fl">1</span><span class="op">:</span><span class="fl">4</span><span class="op">]</span>, <span class="fl">2</span>, <span class="kw">function</span><span class="op">(</span><span class="va">x</span><span class="op">)</span> <span class="fu"><a href="https://rdrr.io/r/stats/cor.html" class="external-link">var</a></span><span class="op">(</span><span class="va">x</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">## Sepal.Length  Sepal.Width Petal.Length  Petal.Width </span></span>
<span><span class="co">##    0.6856935    0.1899794    3.1162779    0.5810063</span></span></code></pre>
<p>Then, the distance between objects 1 and 2 is</p>
<div class="sourceCode" id="cb23"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="op">(</span><span class="fl">5.1</span><span class="op">-</span><span class="fl">4.9</span><span class="op">)</span><span class="op">^</span><span class="fl">2</span><span class="op">/</span><span class="fl">0.6856935</span> <span class="op">+</span> <span class="op">(</span><span class="fl">3.5</span> <span class="op">-</span> <span class="fl">3.0</span><span class="op">)</span><span class="op">^</span><span class="fl">2</span><span class="op">/</span><span class="fl">0.1899794</span> <span class="op">+</span> <span class="op">(</span><span class="fl">1.4</span><span class="op">-</span><span class="fl">1.4</span><span class="op">)</span><span class="op">^</span><span class="fl">2</span><span class="op">/</span><span class="fl">3.1162779</span> <span class="op">+</span></span>
<span>  <span class="op">(</span><span class="fl">0.2</span><span class="op">-</span><span class="fl">0.2</span><span class="op">)</span><span class="op">^</span><span class="fl">2</span><span class="op">/</span><span class="fl">0.5810063</span></span></code></pre></div>
<pre><code><span><span class="co">## [1] 1.374267</span></span></code></pre>
<p><a href="#intro">(Back to Intoduction)</a></p>
</div>
<div class="section level5">
<h5 id="se">2.A.5. squared Euclidean (<code>method = "se"</code>)<a class="anchor" aria-label="anchor" href="#se"></a>
</h5>
<div class="sourceCode" id="cb25"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co">#calculate the squared Euclidean distance of all iris objects</span></span>
<span><span class="va">sedist</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/distNumeric.html">distNumeric</a></span><span class="op">(</span><span class="va">num</span>, <span class="va">num</span>, method <span class="op">=</span> <span class="st">"se"</span><span class="op">)</span></span>
<span><span class="co">#show the distance among objects 1 to 3</span></span>
<span><span class="va">sedist</span><span class="op">[</span><span class="fl">1</span><span class="op">:</span><span class="fl">3</span>,<span class="fl">1</span><span class="op">:</span><span class="fl">3</span><span class="op">]</span></span></code></pre></div>
<pre><code><span><span class="co">##      1    2    3</span></span>
<span><span class="co">## 1 0.00 0.29 0.26</span></span>
<span><span class="co">## 2 0.29 0.00 0.09</span></span>
<span><span class="co">## 3 0.26 0.09 0.00</span></span></code></pre>
<p>The squared Euclidean distance between objects 1 and 2 is
<code>0.29</code>. It is computed by</p>
<div class="sourceCode" id="cb27"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="op">(</span><span class="fl">5.1</span><span class="op">-</span><span class="fl">4.9</span><span class="op">)</span><span class="op">^</span><span class="fl">2</span> <span class="op">+</span> <span class="op">(</span><span class="fl">3.5</span> <span class="op">-</span> <span class="fl">3.0</span><span class="op">)</span><span class="op">^</span><span class="fl">2</span> <span class="op">+</span> <span class="op">(</span><span class="fl">1.4</span><span class="op">-</span><span class="fl">1.4</span><span class="op">)</span><span class="op">^</span><span class="fl">2</span> <span class="op">+</span> <span class="op">(</span><span class="fl">0.2</span><span class="op">-</span><span class="fl">0.2</span><span class="op">)</span><span class="op">^</span><span class="fl">2</span></span></code></pre></div>
<pre><code><span><span class="co">## [1] 0.29</span></span></code></pre>
<p><a href="#intro">(Back to Intoduction)</a></p>
</div>
</div>
<div class="section level4">
<h4 id="b--binary-or-categorical-variables">2.B. Binary or Categorical variables<a class="anchor" aria-label="anchor" href="#b--binary-or-categorical-variables"></a>
</h4>
<p>There are two functions to calculate the binary and categorical
variables. The first is <code>matching</code> to compute the simple
matching distance and the second is <code>cooccur</code> to calculate
the co-occurrence distance. To introduce what these functions do, the
<code>bin</code> data set is generated.</p>
<div class="sourceCode" id="cb29"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/Random.html" class="external-link">set.seed</a></span><span class="op">(</span><span class="fl">1</span><span class="op">)</span></span>
<span><span class="va">bin</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html" class="external-link">matrix</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/sample.html" class="external-link">sample</a></span><span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="fl">2</span>, <span class="fl">4</span><span class="op">*</span><span class="fl">2</span>, replace <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span>, <span class="fl">4</span>, <span class="fl">2</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/colnames.html" class="external-link">rownames</a></span><span class="op">(</span><span class="va">bin</span><span class="op">)</span> <span class="op">&lt;-</span> <span class="fl">1</span><span class="op">:</span><span class="fu"><a href="https://rdrr.io/r/base/nrow.html" class="external-link">nrow</a></span><span class="op">(</span><span class="va">bin</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/colnames.html" class="external-link">colnames</a></span><span class="op">(</span><span class="va">bin</span><span class="op">)</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"x"</span>, <span class="st">"y"</span><span class="op">)</span></span></code></pre></div>
<div class="section level5">
<h5 id="sm">2.B.1. Simple matching (<code>matching</code>)<a class="anchor" aria-label="anchor" href="#sm"></a>
</h5>
<p>The <code>matching</code> function calculates the simple matching
distance between two data sets. If the two data sets are identical, the
functions calculates the distance among objects within the data set. The
simple matching distance is equal to the proportion of the mis-match
categories.</p>
<div class="sourceCode" id="cb30"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">bin</span></span></code></pre></div>
<pre><code><span><span class="co">##   x y</span></span>
<span><span class="co">## 1 1 2</span></span>
<span><span class="co">## 2 2 1</span></span>
<span><span class="co">## 3 1 1</span></span>
<span><span class="co">## 4 1 1</span></span></code></pre>
<div class="sourceCode" id="cb32"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co">#calculate simple matching distance</span></span>
<span><span class="fu"><a href="../reference/matching.html">matching</a></span><span class="op">(</span><span class="va">bin</span>, <span class="va">bin</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">##     1   2   3   4</span></span>
<span><span class="co">## 1 0.0 1.0 0.5 0.5</span></span>
<span><span class="co">## 2 1.0 0.0 0.5 0.5</span></span>
<span><span class="co">## 3 0.5 0.5 0.0 0.0</span></span>
<span><span class="co">## 4 0.5 0.5 0.0 0.0</span></span></code></pre>
<p>As an example of the simple matching distance, the distance between
objects 1 and 2 is calculated by</p>
<div class="sourceCode" id="cb34"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="op">(</span><span class="op">(</span><span class="fl">1</span> <span class="op">==</span> <span class="fl">1</span><span class="op">)</span> <span class="op">+</span> <span class="op">(</span><span class="fl">1</span> <span class="op">==</span> <span class="fl">2</span><span class="op">)</span><span class="op">)</span><span class="op">/</span> <span class="fl">2</span></span></code></pre></div>
<pre><code><span><span class="co">## [1] 0.5</span></span></code></pre>
<p>The distance between objects 1 and 2, which is <code>0.5</code>, is
produced from <em>one mis-match</em> and <em>one match</em> categories
from the two variables (<code>x</code> and <code>y</code>) in the
<code>bin</code> data set. When <code>x1</code> is equal to
<code>x2</code>, for instance, the score is 0. Meanwile, if
<code>x1</code> is not equal to <code>x2</code>, the score is 1. These
scores are also valid in the <code>y</code> variable. Hence, the
distance between objects 1 and 2 is <code>(0+1)/2</code> that is equal
to <code>1/2</code>.</p>
<p><a href="#intro">(Back to Intoduction)</a></p>
</div>
<div class="section level5">
<h5 id="cooc">2.B.2. Co-occurrence distance (<code>cooccur</code>)<a class="anchor" aria-label="anchor" href="#cooc"></a>
</h5>
<p>The co-ocurrence distance <span class="citation">(Ahmad and Dey 2007;
Harikumar and PV 2015)</span> can be calculated via the
<code>cooccur</code> function. To calculate the distance between
objects, the distribution of the variables are taken into consideration.
Compared to the simple matching distance, the co-occurrence distance
redefines the score of <strong>match</strong> and
<strong>mis-match</strong> categories such that they are
<em>unnecessary</em> to be <code>0</code> and <code>1</code>,
respectively. Due to relying on the distribution of all inclusion
variables, the co-occurence distance of a data set with a single
variable is <strong>absent</strong>.</p>
<p>The co-occurrence distance of the <code>bin</code> data set is</p>
<div class="sourceCode" id="cb36"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co">#calculate co-occurrence distance</span></span>
<span><span class="fu"><a href="../reference/cooccur.html">cooccur</a></span><span class="op">(</span><span class="va">bin</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">##           1         2         3         4</span></span>
<span><span class="co">## 1 0.0000000 0.6666667 0.3333333 0.3333333</span></span>
<span><span class="co">## 2 0.6666667 0.0000000 0.3333333 0.3333333</span></span>
<span><span class="co">## 3 0.3333333 0.3333333 0.0000000 0.0000000</span></span>
<span><span class="co">## 4 0.3333333 0.3333333 0.0000000 0.0000000</span></span></code></pre>
<p>To show how co-occurrence distance is calculated, the distance
between objects 1 and 2 is presented.</p>
<div class="sourceCode" id="cb38"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">bin</span></span></code></pre></div>
<pre><code><span><span class="co">##   x y</span></span>
<span><span class="co">## 1 1 2</span></span>
<span><span class="co">## 2 2 1</span></span>
<span><span class="co">## 3 1 1</span></span>
<span><span class="co">## 4 1 1</span></span></code></pre>
<p><strong>Step 1</strong> Creating cross tabulations</p>
<div class="sourceCode" id="cb40"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co">#cross tabulation to define score in the y variable</span></span>
<span><span class="op">(</span><span class="va">tab.y</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/table.html" class="external-link">table</a></span><span class="op">(</span><span class="va">bin</span><span class="op">[</span>,<span class="st">'x'</span><span class="op">]</span>, <span class="va">bin</span><span class="op">[</span>,<span class="st">'y'</span><span class="op">]</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">##    </span></span>
<span><span class="co">##     1 2</span></span>
<span><span class="co">##   1 2 1</span></span>
<span><span class="co">##   2 1 0</span></span></code></pre>
<div class="sourceCode" id="cb42"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co">#cross tabulation to define score in the x variable</span></span>
<span><span class="op">(</span><span class="va">tab.x</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/table.html" class="external-link">table</a></span><span class="op">(</span><span class="va">bin</span><span class="op">[</span>,<span class="st">'y'</span><span class="op">]</span>, <span class="va">bin</span><span class="op">[</span>,<span class="st">'x'</span><span class="op">]</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">##    </span></span>
<span><span class="co">##     1 2</span></span>
<span><span class="co">##   1 2 1</span></span>
<span><span class="co">##   2 1 0</span></span></code></pre>
<p><strong>Step 2</strong> Calculating the column proportions of each
cross tabulation</p>
<div class="sourceCode" id="cb44"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co">#proportion in the y variable</span></span>
<span><span class="op">(</span><span class="va">prop.y</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/apply.html" class="external-link">apply</a></span><span class="op">(</span><span class="va">tab.y</span>, <span class="fl">2</span>, <span class="kw">function</span><span class="op">(</span><span class="va">x</span><span class="op">)</span> <span class="va">x</span><span class="op">/</span><span class="fu"><a href="https://rdrr.io/r/base/sum.html" class="external-link">sum</a></span><span class="op">(</span><span class="va">x</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">##    </span></span>
<span><span class="co">##             1 2</span></span>
<span><span class="co">##   1 0.6666667 1</span></span>
<span><span class="co">##   2 0.3333333 0</span></span></code></pre>
<div class="sourceCode" id="cb46"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co">#proportion in the x variable</span></span>
<span><span class="op">(</span><span class="va">prop.x</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/apply.html" class="external-link">apply</a></span><span class="op">(</span><span class="va">tab.x</span>, <span class="fl">2</span>, <span class="kw">function</span><span class="op">(</span><span class="va">x</span><span class="op">)</span> <span class="va">x</span><span class="op">/</span><span class="fu"><a href="https://rdrr.io/r/base/sum.html" class="external-link">sum</a></span><span class="op">(</span><span class="va">x</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">##    </span></span>
<span><span class="co">##             1 2</span></span>
<span><span class="co">##   1 0.6666667 1</span></span>
<span><span class="co">##   2 0.3333333 0</span></span></code></pre>
<p><strong>Step 3</strong> Finding the maximum values for each row of
the proportion</p>
<div class="sourceCode" id="cb48"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co">#maximum proportion in the y variable</span></span>
<span><span class="op">(</span><span class="va">max.y</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/apply.html" class="external-link">apply</a></span><span class="op">(</span><span class="va">prop.y</span>, <span class="fl">2</span>, <span class="kw">function</span><span class="op">(</span><span class="va">x</span><span class="op">)</span> <span class="fu"><a href="https://rdrr.io/r/base/Extremes.html" class="external-link">max</a></span><span class="op">(</span><span class="va">x</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">##         1         2 </span></span>
<span><span class="co">## 0.6666667 1.0000000</span></span></code></pre>
<div class="sourceCode" id="cb50"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co">#maximum proportion in the x variable</span></span>
<span><span class="op">(</span><span class="va">max.x</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/apply.html" class="external-link">apply</a></span><span class="op">(</span><span class="va">prop.x</span>, <span class="fl">2</span>, <span class="kw">function</span><span class="op">(</span><span class="va">x</span><span class="op">)</span> <span class="fu"><a href="https://rdrr.io/r/base/Extremes.html" class="external-link">max</a></span><span class="op">(</span><span class="va">x</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">##         1         2 </span></span>
<span><span class="co">## 0.6666667 1.0000000</span></span></code></pre>
<p><strong>Step 4</strong> Defining the scores of each variable</p>
<p>The score is obtained by a summation of the maximum value subtracted
and divided by a constant. The constant has a value depending on the
number of inclusion variables. For the <code>bin</code> data set, the
constant is <code>1</code> because both <code>x</code> and
<code>y</code> variables are only depended on <em>one</em> other
variable, i.e. <code>x</code> depends on the distribution of
<code>y</code> and <code>y</code> relies on the distribution of
<code>x</code>.</p>
<div class="sourceCode" id="cb52"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co">#score mis-match in the y variable</span></span>
<span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/sum.html" class="external-link">sum</a></span><span class="op">(</span><span class="va">max.y</span><span class="op">)</span> <span class="op">-</span> <span class="fl">1</span><span class="op">)</span><span class="op">/</span><span class="fl">1</span></span></code></pre></div>
<pre><code><span><span class="co">## [1] 0.6666667</span></span></code></pre>
<div class="sourceCode" id="cb54"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co">#score mis-match in the x variable</span></span>
<span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/sum.html" class="external-link">sum</a></span><span class="op">(</span><span class="va">max.x</span><span class="op">)</span> <span class="op">-</span> <span class="fl">1</span><span class="op">)</span><span class="op">/</span><span class="fl">1</span></span></code></pre></div>
<pre><code><span><span class="co">## [1] 0.6666667</span></span></code></pre>
<p>It can be implied that the score for mis-match categories are
<code>0.5</code> and <code>0.67</code> in the <code>x</code> and
<code>y</code> variables, respectively. Note that the score for
<strong>match</strong> categories is <strong>alwalys
<code>0</code></strong>. Thus, the distance between objects 1 and 2 is
<code>0+0.6666667 = 0.6666667</code> and between objects 1 and 3 is
<code>0.5+0.6666667 = 1.1666667</code></p>
<p><a href="#intro">(Back to Intoduction)</a></p>
</div>
</div>
<div class="section level4">
<h4 id="c--mixed-variables-distmix">2.C. Mixed variables (<code>distmix</code>)<a class="anchor" aria-label="anchor" href="#c--mixed-variables-distmix"></a>
</h4>
<p>There are six available distance methods for a mixed variable data
set. The <code>distmix</code> function calculates mixed variable
distance in which it requires <em>column id</em> of each class of
variables. The <code>mixdata</code> data set is generated to describe
each method in the <code>distmix</code> function.</p>
<div class="sourceCode" id="cb56"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">cat</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html" class="external-link">matrix</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">1</span>, <span class="fl">3</span>, <span class="fl">2</span>, <span class="fl">1</span>, <span class="fl">3</span>, <span class="fl">1</span>, <span class="fl">2</span>, <span class="fl">2</span><span class="op">)</span>, <span class="fl">4</span>, <span class="fl">2</span><span class="op">)</span></span>
<span><span class="va">mixdata</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/cbind.html" class="external-link">cbind</a></span><span class="op">(</span><span class="va">iris</span><span class="op">[</span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="fl">2</span>, <span class="fl">51</span><span class="op">:</span><span class="fl">52</span><span class="op">)</span>,<span class="fl">3</span><span class="op">:</span><span class="fl">4</span><span class="op">]</span>, <span class="va">bin</span>, <span class="va">cat</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/colnames.html" class="external-link">rownames</a></span><span class="op">(</span><span class="va">mixdata</span><span class="op">)</span> <span class="op">&lt;-</span> <span class="fl">1</span><span class="op">:</span><span class="fu"><a href="https://rdrr.io/r/base/nrow.html" class="external-link">nrow</a></span><span class="op">(</span><span class="va">mixdata</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/colnames.html" class="external-link">colnames</a></span><span class="op">(</span><span class="va">mixdata</span><span class="op">)</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/paste.html" class="external-link">paste</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"num"</span><span class="op">)</span>, <span class="fl">1</span><span class="op">:</span><span class="fl">2</span>, sep <span class="op">=</span> <span class="st">""</span><span class="op">)</span>, </span>
<span>                       <span class="fu"><a href="https://rdrr.io/r/base/paste.html" class="external-link">paste</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"bin"</span><span class="op">)</span>, <span class="fl">1</span><span class="op">:</span><span class="fl">2</span>, sep <span class="op">=</span> <span class="st">""</span><span class="op">)</span>, </span>
<span>                       <span class="fu"><a href="https://rdrr.io/r/base/paste.html" class="external-link">paste</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"cat"</span><span class="op">)</span>, <span class="fl">1</span><span class="op">:</span><span class="fl">2</span>, sep <span class="op">=</span> <span class="st">""</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<div class="section level5">
<h5 id="gower">2.C.1 Gower (<code>method = "gower"</code>)<a class="anchor" aria-label="anchor" href="#gower"></a>
</h5>
<p>The <code>method = "gower"</code> in the <code>distmix</code>
function calculates the <span class="citation">Gower (1971)</span>
distance. The original Gower distance allows missing values, while it is
not allowed in the <code>distmix</code> function.</p>
<div class="sourceCode" id="cb57"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">mixdata</span></span></code></pre></div>
<pre><code><span><span class="co">##   num1 num2 bin1 bin2 cat1 cat2</span></span>
<span><span class="co">## 1  1.4  0.2    1    2    1    3</span></span>
<span><span class="co">## 2  1.4  0.2    2    1    3    1</span></span>
<span><span class="co">## 3  4.7  1.4    1    1    2    2</span></span>
<span><span class="co">## 4  4.5  1.5    1    1    1    2</span></span></code></pre>
<p>The Gower distance of the <code>mixdata</code> data set is</p>
<div class="sourceCode" id="cb59"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co">#calculate the Gower distance</span></span>
<span><span class="fu"><a href="../reference/distmix.html">distmix</a></span><span class="op">(</span><span class="va">mixdata</span>, method <span class="op">=</span> <span class="st">"gower"</span>, idnum <span class="op">=</span> <span class="fl">1</span><span class="op">:</span><span class="fl">2</span>, idbin <span class="op">=</span> <span class="fl">3</span><span class="op">:</span><span class="fl">4</span>, idcat <span class="op">=</span> <span class="fl">5</span><span class="op">:</span><span class="fl">6</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">##           1         2         3         4</span></span>
<span><span class="co">## 1 0.0000000 0.6666667 0.8205128 0.6565657</span></span>
<span><span class="co">## 2 0.6666667 0.0000000 0.8205128 0.8232323</span></span>
<span><span class="co">## 3 0.8205128 0.8205128 0.0000000 0.1895882</span></span>
<span><span class="co">## 4 0.6565657 0.8232323 0.1895882 0.0000000</span></span></code></pre>
<p>As an example, the distance between objects 3 and 4 is presented. The
range of each numerical variables is necessary.</p>
<div class="sourceCode" id="cb61"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co">#extract the range of each numerical variable</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/apply.html" class="external-link">apply</a></span><span class="op">(</span><span class="va">mixdata</span><span class="op">[</span>,<span class="fl">1</span><span class="op">:</span><span class="fl">2</span><span class="op">]</span>, <span class="fl">2</span>, <span class="kw">function</span><span class="op">(</span><span class="va">x</span><span class="op">)</span> <span class="fu"><a href="https://rdrr.io/r/base/Extremes.html" class="external-link">max</a></span><span class="op">(</span><span class="va">x</span><span class="op">)</span><span class="op">-</span><span class="fu"><a href="https://rdrr.io/r/base/Extremes.html" class="external-link">min</a></span><span class="op">(</span><span class="va">x</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">## num1 num2 </span></span>
<span><span class="co">##  3.3  1.3</span></span></code></pre>
<p>The Gower distance calculates the Gower similarity first. In the
Gower similarity, the <strong>mis-match</strong> categories in the
binary/ categorical variables are scored <strong>0</strong> and the
<strong>match</strong> categories are <strong>1</strong>. Meanwhile, in
the numerical variables, 1 is subtracted by a ratio between the absolute
difference and its range. Then, the Gower similarity can be weighted by
the number of variables. Thus, the Gower similarity between objects 3
and 4 is</p>
<div class="sourceCode" id="cb63"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co">#the Gower similarity</span></span>
<span><span class="op">(</span><span class="va">gowsim</span> <span class="op">&lt;-</span> <span class="op">(</span><span class="op">(</span><span class="fl">1</span><span class="op">-</span><span class="fu"><a href="https://rdrr.io/r/base/MathFun.html" class="external-link">abs</a></span><span class="op">(</span><span class="fl">4.7</span><span class="op">-</span><span class="fl">4.5</span><span class="op">)</span><span class="op">/</span><span class="fl">3.3</span><span class="op">)</span> <span class="op">+</span> <span class="op">(</span><span class="fl">1</span><span class="op">-</span><span class="fu"><a href="https://rdrr.io/r/base/MathFun.html" class="external-link">abs</a></span><span class="op">(</span><span class="fl">1.4</span><span class="op">-</span><span class="fl">1.5</span><span class="op">)</span><span class="op">/</span><span class="fl">1.3</span><span class="op">)</span> <span class="op">+</span> <span class="fl">1</span> <span class="op">+</span> <span class="fl">1</span> <span class="op">+</span> <span class="fl">0</span> <span class="op">+</span> <span class="fl">1</span><span class="op">)</span><span class="op">/</span> <span class="fl">6</span> <span class="op">)</span> </span></code></pre></div>
<pre><code><span><span class="co">## [1] 0.8104118</span></span></code></pre>
<p>The Gower distance is obtained by subtracting 1 with the Gower
similarity. The distance between objects 3 and 4 is then</p>
<div class="sourceCode" id="cb65"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co">#the Gower distance</span></span>
<span><span class="fl">1</span> <span class="op">-</span> <span class="va">gowsim</span></span></code></pre></div>
<pre><code><span><span class="co">## [1] 0.1895882</span></span></code></pre>
<p><a href="#intro">(Back to Intoduction)</a></p>
</div>
<div class="section level5">
<h5 id="wishart">2.C.2 Wishart (<code>method = "wishart"</code>)<a class="anchor" aria-label="anchor" href="#wishart"></a>
</h5>
<p>The <span class="citation">Wishart (2003)</span> distance can be
calculated via <code>method = "wishart"</code>. Although it allows
missing values, it is again illegitimate in the <code>distmix</code>
function. The Wishart distance for the <code>mixdata</code> is</p>
<div class="sourceCode" id="cb67"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co">#calculate the Wishart distance</span></span>
<span><span class="fu"><a href="../reference/distmix.html">distmix</a></span><span class="op">(</span><span class="va">mixdata</span>, method <span class="op">=</span> <span class="st">"wishart"</span>, idnum <span class="op">=</span> <span class="fl">1</span><span class="op">:</span><span class="fl">2</span>, idbin <span class="op">=</span> <span class="fl">3</span><span class="op">:</span><span class="fl">4</span>, idcat <span class="op">=</span> <span class="fl">5</span><span class="op">:</span><span class="fl">6</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">##           1         2         3         4</span></span>
<span><span class="co">## 1 0.0000000 0.8164966 1.2206686 1.1578998</span></span>
<span><span class="co">## 2 0.8164966 0.0000000 1.2206686 1.2277616</span></span>
<span><span class="co">## 3 1.2206686 1.2206686 0.0000000 0.4144946</span></span>
<span><span class="co">## 4 1.1578998 1.2277616 0.4144946 0.0000000</span></span></code></pre>
<p>To calculate the Wishart distance, the variance of each numerical
variable is required. It weighs the squared difference of a numerical
variable.</p>
<div class="sourceCode" id="cb69"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co">#extract the variance of each numerical variable</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/apply.html" class="external-link">apply</a></span><span class="op">(</span><span class="va">mixdata</span><span class="op">[</span>,<span class="fl">1</span><span class="op">:</span><span class="fl">2</span><span class="op">]</span>, <span class="fl">2</span>, <span class="kw">function</span><span class="op">(</span><span class="va">x</span><span class="op">)</span> <span class="fu"><a href="https://rdrr.io/r/stats/cor.html" class="external-link">var</a></span><span class="op">(</span><span class="va">x</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">##   num1   num2 </span></span>
<span><span class="co">## 3.4200 0.5225</span></span></code></pre>
<p>Meanwhile, the <strong>mis-match</strong> categories in the binary/
categorical variables are scored <strong>1</strong> and the
<strong>match</strong> categories are <strong>0</strong>. Then, all
score of the variables is added and squared rooted. Thus, the distance
between objects 3 and 4 is</p>
<div class="sourceCode" id="cb71"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">wish</span> <span class="op">&lt;-</span> <span class="op">(</span><span class="op">(</span><span class="op">(</span><span class="fl">4.7</span><span class="op">-</span><span class="fl">4.5</span><span class="op">)</span><span class="op">^</span><span class="fl">2</span><span class="op">/</span><span class="fl">3.42</span><span class="op">)</span> <span class="op">+</span> <span class="op">(</span><span class="op">(</span><span class="fl">1.4</span><span class="op">-</span><span class="fl">1.5</span><span class="op">)</span><span class="op">^</span><span class="fl">2</span><span class="op">/</span><span class="fl">0.5225</span><span class="op">)</span> <span class="op">+</span> <span class="fl">0</span> <span class="op">+</span> <span class="fl">0</span> <span class="op">+</span> <span class="fl">1</span> <span class="op">+</span> <span class="fl">0</span><span class="op">)</span><span class="op">/</span> <span class="fl">6</span> </span>
<span><span class="co">#the Wishart distance</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/MathFun.html" class="external-link">sqrt</a></span><span class="op">(</span><span class="va">wish</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">## [1] 0.4144946</span></span></code></pre>
<p><a href="#intro">(Back to Intoduction)</a></p>
</div>
<div class="section level5">
<h5 id="podani">2.C.3 Podani (<code>method = "podani"</code>)<a class="anchor" aria-label="anchor" href="#podani"></a>
</h5>
<p>The <code>method = "podani"</code> in the <code>distmix</code>
function calculates the <span class="citation">Podani (1999)</span>
distance. Similar to The Gower and Wishart distances, it allows missing
values, yet it is not allowed in the <code>distmix</code> function. The
Podani distance for the <code>mixdata</code> is</p>
<div class="sourceCode" id="cb73"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co">#calculate Podani distance</span></span>
<span><span class="fu"><a href="../reference/distmix.html">distmix</a></span><span class="op">(</span><span class="va">mixdata</span>, method <span class="op">=</span> <span class="st">"podani"</span>, idnum <span class="op">=</span> <span class="fl">1</span><span class="op">:</span><span class="fl">2</span>, idbin <span class="op">=</span> <span class="fl">3</span><span class="op">:</span><span class="fl">4</span>, idcat <span class="op">=</span> <span class="fl">5</span><span class="op">:</span><span class="fl">6</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">##          1        2        3        4</span></span>
<span><span class="co">## 1 0.000000 2.000000 2.202742 1.970396</span></span>
<span><span class="co">## 2 2.000000 0.000000 2.202742 2.209629</span></span>
<span><span class="co">## 3 2.202742 2.202742 0.000000 1.004784</span></span>
<span><span class="co">## 4 1.970396 2.209629 1.004784 0.000000</span></span></code></pre>
<p>The Podani and Wishart distances are similar. They are different in
the denumerator for the numerical variables. Instead of a variance, the
Podani distance applies the squared range for a numerical variable.
Unlike the Gower and Podani distances, the number of variables as a
weight is absent in the Podani distance. Hence, the distance between
objects 3 and 4 is</p>
<div class="sourceCode" id="cb75"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">poda</span> <span class="op">&lt;-</span> <span class="op">(</span><span class="op">(</span><span class="fl">4.7</span><span class="op">-</span><span class="fl">4.5</span><span class="op">)</span><span class="op">^</span><span class="fl">2</span><span class="op">/</span><span class="fl">3.3</span><span class="op">^</span><span class="fl">2</span><span class="op">)</span> <span class="op">+</span> <span class="op">(</span><span class="op">(</span><span class="fl">1.4</span><span class="op">-</span><span class="fl">1.5</span><span class="op">)</span><span class="op">^</span><span class="fl">2</span><span class="op">/</span><span class="fl">1.3</span><span class="op">^</span><span class="fl">2</span><span class="op">)</span> <span class="op">+</span> <span class="fl">0</span> <span class="op">+</span> <span class="fl">0</span> <span class="op">+</span> <span class="fl">1</span> <span class="op">+</span> <span class="fl">0</span> </span>
<span><span class="co">#the Podani distance</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/MathFun.html" class="external-link">sqrt</a></span><span class="op">(</span><span class="va">poda</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">## [1] 1.004784</span></span></code></pre>
<p>which is based on data</p>
<pre><code><span><span class="co">##   num1 num2 bin1 bin2 cat1 cat2</span></span>
<span><span class="co">## 3  4.7  1.4    1    1    2    2</span></span>
<span><span class="co">## 4  4.5  1.5    1    1    1    2</span></span></code></pre>
<p><a href="#intro">(Back to Intoduction)</a></p>
</div>
<div class="section level5">
<h5 id="huang">2.C.4 Huang (<code>method = "huang"</code>)<a class="anchor" aria-label="anchor" href="#huang"></a>
</h5>
<p>The <code>method = "huang"</code> in the <code>distmix</code>
function calculates the <span class="citation">Huang (1997)</span>
distance. The Huang distance of the <code>mixdata</code> data set is</p>
<div class="sourceCode" id="cb78"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co">#calculate the Huang distance</span></span>
<span><span class="fu"><a href="../reference/distmix.html">distmix</a></span><span class="op">(</span><span class="va">mixdata</span>, method <span class="op">=</span> <span class="st">"huang"</span>, idnum <span class="op">=</span> <span class="fl">1</span><span class="op">:</span><span class="fl">2</span>, idbin <span class="op">=</span> <span class="fl">3</span><span class="op">:</span><span class="fl">4</span>, idcat <span class="op">=</span> <span class="fl">5</span><span class="op">:</span><span class="fl">6</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">##           1         2         3         4</span></span>
<span><span class="co">## 1  0.000000  5.144332 16.188249 13.872166</span></span>
<span><span class="co">## 2  5.144332  0.000000 16.188249 15.158249</span></span>
<span><span class="co">## 3 16.188249 16.188249  0.000000  1.336083</span></span>
<span><span class="co">## 4 13.872166 15.158249  1.336083  0.000000</span></span></code></pre>
<p>The average standard deviation of the numerical variables is required
to calculate the Huang distance. This measure weighs the binary/
categorical variables.</p>
<div class="sourceCode" id="cb80"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co">#find the average standard deviation of the numerical variables</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/mean.html" class="external-link">mean</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/apply.html" class="external-link">apply</a></span><span class="op">(</span><span class="va">mixdata</span><span class="op">[</span>,<span class="fl">1</span><span class="op">:</span><span class="fl">2</span><span class="op">]</span>, <span class="fl">2</span>, <span class="kw">function</span><span class="op">(</span><span class="va">x</span><span class="op">)</span> <span class="fu"><a href="https://rdrr.io/r/stats/sd.html" class="external-link">sd</a></span><span class="op">(</span><span class="va">x</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">## [1] 1.286083</span></span></code></pre>
<p>While the squared difference of the numerical variables is
calculated, the <strong>mis-match</strong> categories are scored
<strong>1</strong> and the <strong>match</strong> categories are
<strong>0</strong> in the binary/ categorical variables. Thus, the
distance between objects 3 and 4 is</p>
<div class="sourceCode" id="cb82"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="op">(</span><span class="fl">4.7</span><span class="op">-</span><span class="fl">4.5</span><span class="op">)</span><span class="op">^</span><span class="fl">2</span> <span class="op">+</span> <span class="op">(</span><span class="fl">1.4</span><span class="op">-</span><span class="fl">1.5</span><span class="op">)</span><span class="op">^</span><span class="fl">2</span> <span class="op">+</span> <span class="fl">1.286083</span><span class="op">*</span><span class="op">(</span><span class="fl">0</span> <span class="op">+</span> <span class="fl">0</span><span class="op">)</span> <span class="op">+</span> <span class="fl">1.286083</span><span class="op">*</span><span class="op">(</span><span class="fl">1</span> <span class="op">+</span> <span class="fl">0</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">## [1] 1.336083</span></span></code></pre>
<p><a href="#intro">(Back to Intoduction)</a></p>
</div>
<div class="section level5">
<h5 id="harikumar">2.C.5 Harikumar and PV (<code>method = "harikumar"</code>)<a class="anchor" aria-label="anchor" href="#harikumar"></a>
</h5>
<p>The <span class="citation">Harikumar and PV (2015)</span> distance
can be calculated via <code>method = "harikumar"</code>. The Harikumar
and PV distance for the <code>mixdata</code> is</p>
<div class="sourceCode" id="cb84"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co">#calculate Harikumar-PV distance</span></span>
<span><span class="fu"><a href="../reference/distmix.html">distmix</a></span><span class="op">(</span><span class="va">mixdata</span>, method <span class="op">=</span> <span class="st">"harikumar"</span>, idnum <span class="op">=</span> <span class="fl">1</span><span class="op">:</span><span class="fl">2</span>, idbin <span class="op">=</span> <span class="fl">3</span><span class="op">:</span><span class="fl">4</span>, idcat <span class="op">=</span> <span class="fl">5</span><span class="op">:</span><span class="fl">6</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">##     1   2   3   4</span></span>
<span><span class="co">## 1 0.0 4.0 6.5 5.9</span></span>
<span><span class="co">## 2 4.0 0.0 7.5 7.4</span></span>
<span><span class="co">## 3 6.5 7.5 0.0 0.8</span></span>
<span><span class="co">## 4 5.9 7.4 0.8 0.0</span></span></code></pre>
<p>The Harikumar and PV distance requires an absolute difference in the
numerical variables and unweighted simple matching, i.e. Hamming
distance, in the binary variables. For the categorical variables, it
applies co-occurrence distance. The co-occurence distance in the
categorical variables is (for manual calculation see <a href="#cooc">co-occurrence</a> subsection)</p>
<div class="sourceCode" id="cb86"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/cooccur.html">cooccur</a></span><span class="op">(</span><span class="va">mixdata</span><span class="op">[</span>,<span class="fl">5</span><span class="op">:</span><span class="fl">6</span><span class="op">]</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">##     1 2   3   4</span></span>
<span><span class="co">## 1 0.0 2 1.0 0.5</span></span>
<span><span class="co">## 2 2.0 0 2.0 2.0</span></span>
<span><span class="co">## 3 1.0 2 0.0 0.5</span></span>
<span><span class="co">## 4 0.5 2 0.5 0.0</span></span></code></pre>
<p>Hence, the distance between objects 1 and 3 is</p>
<div class="sourceCode" id="cb88"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/MathFun.html" class="external-link">abs</a></span><span class="op">(</span><span class="fl">4.7</span><span class="op">-</span><span class="fl">4.5</span><span class="op">)</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/base/MathFun.html" class="external-link">abs</a></span><span class="op">(</span><span class="fl">1.4</span><span class="op">-</span><span class="fl">1.5</span><span class="op">)</span> <span class="op">+</span> <span class="op">(</span><span class="fl">0</span> <span class="op">+</span> <span class="fl">0</span><span class="op">)</span> <span class="op">+</span> <span class="op">(</span><span class="fl">0.5</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">## [1] 0.8</span></span></code></pre>
<p>where the data are</p>
<pre><code><span><span class="co">##   num1 num2 bin1 bin2 cat1 cat2</span></span>
<span><span class="co">## 3  4.7  1.4    1    1    2    2</span></span>
<span><span class="co">## 4  4.5  1.5    1    1    1    2</span></span></code></pre>
<p><a href="#intro">(Back to Intoduction)</a></p>
</div>
<div class="section level5">
<h5 id="ahmad">2.C.6 Ahmad and Dey (<code>method = "ahmad"</code>)<a class="anchor" aria-label="anchor" href="#ahmad"></a>
</h5>
<p>The <code>method = "ahmad"</code> in the <code>distmix</code>
function calculates the <span class="citation">Ahmad and Dey
(2007)</span> distance. The Ahmad and Dey distance of the
<code>mixdata</code> data set is</p>
<div class="sourceCode" id="cb91"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co">#calculate Ahmad-Dey distance</span></span>
<span><span class="fu"><a href="../reference/distmix.html">distmix</a></span><span class="op">(</span><span class="va">mixdata</span>, method <span class="op">=</span> <span class="st">"ahmad"</span>, idnum <span class="op">=</span> <span class="fl">1</span><span class="op">:</span><span class="fl">2</span>, idbin <span class="op">=</span> <span class="fl">3</span><span class="op">:</span><span class="fl">4</span>, idcat <span class="op">=</span> <span class="fl">5</span><span class="op">:</span><span class="fl">6</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">##          1            2            3            4</span></span>
<span><span class="co">## 1  0.00000 1.074383e+01 1.458000e+01 1.266111e+01</span></span>
<span><span class="co">## 2 10.74383 2.191280e-32 1.678679e+01 1.648827e+01</span></span>
<span><span class="co">## 3 14.58000 1.678679e+01 2.191280e-32 1.611111e-01</span></span>
<span><span class="co">## 4 12.66111 1.648827e+01 1.611111e-01 2.191280e-32</span></span></code></pre>
<p>The Ahmad and dey distance requires a squared difference in the
numerical variables and co-occurrence distance for both the binary and
categorical variables. The co-occurrence distance in the
<code>mixdata</code> data set is</p>
<div class="sourceCode" id="cb93"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/cooccur.html">cooccur</a></span><span class="op">(</span><span class="va">mixdata</span><span class="op">[</span>,<span class="fl">3</span><span class="op">:</span><span class="fl">6</span><span class="op">]</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">##          1             2             3             4</span></span>
<span><span class="co">## 1 0.000000  3.277778e+00  1.500000e+00  1.166667e+00</span></span>
<span><span class="co">## 2 3.277778 -1.480297e-16  2.111111e+00  2.277778e+00</span></span>
<span><span class="co">## 3 1.500000  2.111111e+00 -1.480297e-16  3.333333e-01</span></span>
<span><span class="co">## 4 1.166667  2.277778e+00  3.333333e-01 -1.480297e-16</span></span></code></pre>
<p>Thus, the distance between objects 2 and 3 is</p>
<div class="sourceCode" id="cb95"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="op">(</span><span class="fl">1.4</span><span class="op">-</span><span class="fl">4.7</span><span class="op">)</span><span class="op">^</span><span class="fl">2</span> <span class="op">+</span> <span class="op">(</span><span class="fl">0.2</span><span class="op">-</span><span class="fl">1.4</span><span class="op">)</span><span class="op">^</span><span class="fl">2</span> <span class="op">+</span> <span class="op">(</span><span class="fl">2</span><span class="op">)</span><span class="op">^</span><span class="fl">2</span></span></code></pre></div>
<pre><code><span><span class="co">## [1] 16.33</span></span></code></pre>
<p>which is based on the data</p>
<pre><code><span><span class="co">##   num1 num2 bin1 bin2 cat1 cat2</span></span>
<span><span class="co">## 2  1.4  0.2    2    1    3    1</span></span>
<span><span class="co">## 3  4.7  1.4    1    1    2    2</span></span></code></pre>
<p><a href="#intro">(Back to Intoduction)</a></p>
</div>
</div>
</div>
<div class="section level3">
<h3 id="k-medoids-algorithms">3. K-medoids algorithms<a class="anchor" aria-label="anchor" href="#k-medoids-algorithms"></a>
</h3>
<p>There are some k-medoids algorithms available in this package. They
are the simple and fast k-medoids (<code>fastkmed</code>), k-medoids,
ranked k-medoids (<code>rankkmed</code>), and increasing number of
clusters k-medoids (<code>inckmed</code>). All algorithms have a list of
results, namely the cluster membership, id medoids, and distance of all
objects to their medoid.</p>
<p>In this section, the algorithms are applied in the <code>iris</code>
data set by applying the <code>mrw</code> distance (see <a href="#mrw">Manhattan weighted by range</a>). The number of clusters in
this data set is 3.</p>
<div class="section level4">
<h4 id="sfkm">3.A. Simple and fast k-medoids algorithm
(<code>fastkmed</code>)<a class="anchor" aria-label="anchor" href="#sfkm"></a>
</h4>
<p>The simple and fast k-medoid (SFKM) algorithm has been proposed by
<span class="citation">Park and Jun (2009)</span>. The
<code>fastkmed</code> function runs this algorithm to cluster the
objects. The compulsory inputs are a distance matrix or distance object
and a number of clusters. Hence, the SFKM algorithm for the
<code>iris</code> data set is</p>
<div class="sourceCode" id="cb98"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co">#run the sfkm algorihtm on iris data set with mrw distance</span></span>
<span><span class="op">(</span><span class="va">sfkm</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/fastkmed.html">fastkmed</a></span><span class="op">(</span><span class="va">mrwdist</span>, ncluster <span class="op">=</span> <span class="fl">3</span>, iterate <span class="op">=</span> <span class="fl">50</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">## $cluster</span></span>
<span><span class="co">##   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17  18  19  20 </span></span>
<span><span class="co">##   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1 </span></span>
<span><span class="co">##  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35  36  37  38  39  40 </span></span>
<span><span class="co">##   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1 </span></span>
<span><span class="co">##  41  42  43  44  45  46  47  48  49  50  51  52  53  54  55  56  57  58  59  60 </span></span>
<span><span class="co">##   1   1   1   1   1   1   1   1   1   1   3   3   3   2   3   2   3   2   2   2 </span></span>
<span><span class="co">##  61  62  63  64  65  66  67  68  69  70  71  72  73  74  75  76  77  78  79  80 </span></span>
<span><span class="co">##   2   2   2   2   2   3   2   2   2   2   3   2   2   2   2   3   3   3   2   2 </span></span>
<span><span class="co">##  81  82  83  84  85  86  87  88  89  90  91  92  93  94  95  96  97  98  99 100 </span></span>
<span><span class="co">##   2   2   2   2   2   2   3   2   2   2   2   2   2   2   2   2   2   2   2   2 </span></span>
<span><span class="co">## 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 </span></span>
<span><span class="co">##   3   3   3   3   3   3   2   3   3   3   3   3   3   3   3   3   3   3   3   2 </span></span>
<span><span class="co">## 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 </span></span>
<span><span class="co">##   3   3   3   3   3   3   3   3   3   3   3   3   3   3   2   3   3   3   3   3 </span></span>
<span><span class="co">## 141 142 143 144 145 146 147 148 149 150 </span></span>
<span><span class="co">##   3   3   3   3   3   3   3   3   3   3 </span></span>
<span><span class="co">## </span></span>
<span><span class="co">## $medoid</span></span>
<span><span class="co">## [1]   8  95 148</span></span>
<span><span class="co">## </span></span>
<span><span class="co">## $minimum_distance</span></span>
<span><span class="co">## [1] 45.76718</span></span></code></pre>
<p>Then, a classification table can be obtained.</p>
<div class="sourceCode" id="cb100"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="op">(</span><span class="va">sfkmtable</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/table.html" class="external-link">table</a></span><span class="op">(</span><span class="va">sfkm</span><span class="op">$</span><span class="va">cluster</span>, <span class="va">iris</span><span class="op">[</span>,<span class="fl">5</span><span class="op">]</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">##    </span></span>
<span><span class="co">##     setosa versicolor virginica</span></span>
<span><span class="co">##   1     50          0         0</span></span>
<span><span class="co">##   2      0         39         3</span></span>
<span><span class="co">##   3      0         11        47</span></span></code></pre>
<p>Applying the SFKM algorithm in <code>iris</code> data set with the
Manhattan weighted by range, the misclassification rate is</p>
<div class="sourceCode" id="cb102"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="op">(</span><span class="fl">3</span><span class="op">+</span><span class="fl">11</span><span class="op">)</span><span class="op">/</span><span class="fu"><a href="https://rdrr.io/r/base/sum.html" class="external-link">sum</a></span><span class="op">(</span><span class="va">sfkmtable</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">## [1] 0.09333333</span></span></code></pre>
<p><a href="#intro">(Back to Intoduction)</a></p>
</div>
<div class="section level4">
<h4 id="km">3.B. K-medoids algorithm<a class="anchor" aria-label="anchor" href="#km"></a>
</h4>
<p><span class="citation">Reynolds et al. (2006)</span> has been
proposed a k-medoids (KM) algorithm. It is similar to the <a href="#sfkm">SFKM</a> such that the <code>fastkmed</code> can be
applied. The difference is in the initial medoid selection where the KM
selects the initial medoid randomly. Thus, the KM algorithm for the
<code>iris</code> data set by setting the <code>init</code> is</p>
<div class="sourceCode" id="cb104"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co">#set the initial medoids</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/Random.html" class="external-link">set.seed</a></span><span class="op">(</span><span class="fl">1</span><span class="op">)</span></span>
<span><span class="op">(</span><span class="va">kminit</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/sample.html" class="external-link">sample</a></span><span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="fu"><a href="https://rdrr.io/r/base/nrow.html" class="external-link">nrow</a></span><span class="op">(</span><span class="va">iris</span><span class="op">)</span>, <span class="fl">3</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">## [1]  68 129  43</span></span></code></pre>
<div class="sourceCode" id="cb106"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co">#run the km algorihtm on iris data set with mrw distance</span></span>
<span><span class="op">(</span><span class="va">km</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/fastkmed.html">fastkmed</a></span><span class="op">(</span><span class="va">mrwdist</span>, ncluster <span class="op">=</span> <span class="fl">3</span>, iterate <span class="op">=</span> <span class="fl">50</span>, init <span class="op">=</span> <span class="va">kminit</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">## $cluster</span></span>
<span><span class="co">##   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17  18  19  20 </span></span>
<span><span class="co">##   3   3   3   3   3   3   3   3   3   3   3   3   3   3   3   3   3   3   3   3 </span></span>
<span><span class="co">##  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35  36  37  38  39  40 </span></span>
<span><span class="co">##   3   3   3   3   3   3   3   3   3   3   3   3   3   3   3   3   3   3   3   3 </span></span>
<span><span class="co">##  41  42  43  44  45  46  47  48  49  50  51  52  53  54  55  56  57  58  59  60 </span></span>
<span><span class="co">##   3   3   3   3   3   3   3   3   3   3   2   2   2   1   1   1   2   1   1   1 </span></span>
<span><span class="co">##  61  62  63  64  65  66  67  68  69  70  71  72  73  74  75  76  77  78  79  80 </span></span>
<span><span class="co">##   1   1   1   1   1   2   1   1   1   1   2   1   1   1   1   2   1   2   1   1 </span></span>
<span><span class="co">##  81  82  83  84  85  86  87  88  89  90  91  92  93  94  95  96  97  98  99 100 </span></span>
<span><span class="co">##   1   1   1   1   1   1   2   1   1   1   1   1   1   1   1   1   1   1   1   1 </span></span>
<span><span class="co">## 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 </span></span>
<span><span class="co">##   2   2   2   2   2   2   1   2   2   2   2   2   2   2   2   2   2   2   2   1 </span></span>
<span><span class="co">## 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 </span></span>
<span><span class="co">##   2   2   2   2   2   2   2   2   2   2   2   2   2   2   1   2   2   2   2   2 </span></span>
<span><span class="co">## 141 142 143 144 145 146 147 148 149 150 </span></span>
<span><span class="co">##   2   2   2   2   2   2   2   2   2   2 </span></span>
<span><span class="co">## </span></span>
<span><span class="co">## $medoid</span></span>
<span><span class="co">## [1] 100 148   8</span></span>
<span><span class="co">## </span></span>
<span><span class="co">## $minimum_distance</span></span>
<span><span class="co">## [1] 48.8411</span></span></code></pre>
<p>The classification table of the KM algorithm is</p>
<div class="sourceCode" id="cb108"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="op">(</span><span class="va">kmtable</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/table.html" class="external-link">table</a></span><span class="op">(</span><span class="va">km</span><span class="op">$</span><span class="va">cluster</span>, <span class="va">iris</span><span class="op">[</span>,<span class="fl">5</span><span class="op">]</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">##    </span></span>
<span><span class="co">##     setosa versicolor virginica</span></span>
<span><span class="co">##   1      0         41         3</span></span>
<span><span class="co">##   2      0          9        47</span></span>
<span><span class="co">##   3     50          0         0</span></span></code></pre>
<p>with the misclassification rate</p>
<div class="sourceCode" id="cb110"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="op">(</span><span class="fl">3</span><span class="op">+</span><span class="fl">9</span><span class="op">)</span><span class="op">/</span><span class="fu"><a href="https://rdrr.io/r/base/sum.html" class="external-link">sum</a></span><span class="op">(</span><span class="va">kmtable</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">## [1] 0.08</span></span></code></pre>
<p>Compared to the <a href="#sfkm">SFKM</a> algorithm, which has
<code>9.33</code>% misclassification, the misclassification of the KM
algorithm is slightly better (<code>8</code>%).</p>
<p><a href="#intro">(Back to Intoduction)</a></p>
</div>
<div class="section level4">
<h4 id="rkm">3.C. Rank k-medoids algorithm (<code>rankkmed</code>)<a class="anchor" aria-label="anchor" href="#rkm"></a>
</h4>
<p>A rank k-medoids (RKM) has been proposed by <span class="citation">Zadegan, Mirzaie, and Sadoughi (2013)</span>. The
<code>rankkmed</code> function runs the RKM algorithm. The
<code>m</code> argument is introduced to calculate a hostility score.
The <code>m</code> indicates how many closest objects is selected. The
selected objects as initial medoids in the RKM is randomly assigned. The
RKM algorithm for the <code>iris</code> data set by setting
<code>m = 10</code> is then</p>
<div class="sourceCode" id="cb112"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co">#run the rkm algorihtm on iris data set with mrw distance and m = 10</span></span>
<span><span class="op">(</span><span class="va">rkm</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/rankkmed.html">rankkmed</a></span><span class="op">(</span><span class="va">mrwdist</span>, ncluster <span class="op">=</span> <span class="fl">3</span>, m <span class="op">=</span> <span class="fl">10</span>, iterate <span class="op">=</span> <span class="fl">50</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">## $cluster</span></span>
<span><span class="co">##   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17  18  19  20 </span></span>
<span><span class="co">##   2   2   1   1   2   2   1   2   1   2   2   2   1   1   2   2   2   2   2   2 </span></span>
<span><span class="co">##  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35  36  37  38  39  40 </span></span>
<span><span class="co">##   2   2   1   2   2   2   2   2   2   1   1   2   2   2   2   2   2   2   1   2 </span></span>
<span><span class="co">##  41  42  43  44  45  46  47  48  49  50  51  52  53  54  55  56  57  58  59  60 </span></span>
<span><span class="co">##   2   1   1   2   2   1   2   1   2   2   3   3   3   3   3   3   3   3   3   3 </span></span>
<span><span class="co">##  61  62  63  64  65  66  67  68  69  70  71  72  73  74  75  76  77  78  79  80 </span></span>
<span><span class="co">##   3   3   3   3   3   3   3   3   3   3   3   3   3   3   3   3   3   3   3   3 </span></span>
<span><span class="co">##  81  82  83  84  85  86  87  88  89  90  91  92  93  94  95  96  97  98  99 100 </span></span>
<span><span class="co">##   3   3   3   3   3   3   3   3   3   3   3   3   3   3   3   3   3   3   3   3 </span></span>
<span><span class="co">## 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 </span></span>
<span><span class="co">##   3   3   3   3   3   3   3   3   3   3   3   3   3   3   3   3   3   3   3   3 </span></span>
<span><span class="co">## 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 </span></span>
<span><span class="co">##   3   3   3   3   3   3   3   3   3   3   3   3   3   3   3   3   3   3   3   3 </span></span>
<span><span class="co">## 141 142 143 144 145 146 147 148 149 150 </span></span>
<span><span class="co">##   3   3   3   3   3   3   3   3   3   3 </span></span>
<span><span class="co">## </span></span>
<span><span class="co">## $medoid</span></span>
<span><span class="co">## [1] "3"  "50" "55"</span></span>
<span><span class="co">## </span></span>
<span><span class="co">## $minimum_distance</span></span>
<span><span class="co">## [1] 65.20221</span></span></code></pre>
<p>Then, a classification table is attained by</p>
<div class="sourceCode" id="cb114"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="op">(</span><span class="va">rkmtable</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/table.html" class="external-link">table</a></span><span class="op">(</span><span class="va">rkm</span><span class="op">$</span><span class="va">cluster</span>, <span class="va">iris</span><span class="op">[</span>,<span class="fl">5</span><span class="op">]</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">##    </span></span>
<span><span class="co">##     setosa versicolor virginica</span></span>
<span><span class="co">##   1     14          0         0</span></span>
<span><span class="co">##   2     36          0         0</span></span>
<span><span class="co">##   3      0         50        50</span></span></code></pre>
<p>The misclassification proportion is</p>
<div class="sourceCode" id="cb116"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="op">(</span><span class="fl">3</span><span class="op">+</span><span class="fl">3</span><span class="op">)</span><span class="op">/</span><span class="fu"><a href="https://rdrr.io/r/base/sum.html" class="external-link">sum</a></span><span class="op">(</span><span class="va">rkmtable</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">## [1] 0.04</span></span></code></pre>
<p>With <code>4</code>% misclassification rate, the RKM algorithm is the
best among the three previous algorithms.</p>
<p><a href="#intro">(Back to Intoduction)</a></p>
</div>
<div class="section level4">
<h4 id="inckm">3.D. Increasing number of clusters k-medoids algorithm
(<code>inckmed</code>)<a class="anchor" aria-label="anchor" href="#inckm"></a>
</h4>
<p><span class="citation">Yu et al. (2018)</span> has been proposed an
increasing number of clusters k-medoids (INCKM) algorithm. This
algorithm is implemented in the <code>inckmed</code> function. The
<code>alpha</code> argument indicates a stretch factor to select the
initial medoids. The <a href="#sfkm">SFKM</a>, <a href="#km">KM</a> and
<a href="#inckm">INCKM</a> are similar algorithm with a different way to
select the initial medoids. The INCKM algorithm of the <code>iris</code>
data set with <code>alpha = 1.1</code> is</p>
<div class="sourceCode" id="cb118"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co">#run the inckm algorihtm on iris data set with mrw distance and alpha = 1.2</span></span>
<span><span class="op">(</span><span class="va">inckm</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/inckmed.html">inckmed</a></span><span class="op">(</span><span class="va">mrwdist</span>, ncluster <span class="op">=</span> <span class="fl">3</span>, alpha <span class="op">=</span> <span class="fl">1.1</span>, iterate <span class="op">=</span> <span class="fl">50</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">## $cluster</span></span>
<span><span class="co">##   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17  18  19  20 </span></span>
<span><span class="co">##   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1 </span></span>
<span><span class="co">##  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35  36  37  38  39  40 </span></span>
<span><span class="co">##   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1 </span></span>
<span><span class="co">##  41  42  43  44  45  46  47  48  49  50  51  52  53  54  55  56  57  58  59  60 </span></span>
<span><span class="co">##   1   1   1   1   1   1   1   1   1   1   3   2   3   2   2   2   2   2   2   2 </span></span>
<span><span class="co">##  61  62  63  64  65  66  67  68  69  70  71  72  73  74  75  76  77  78  79  80 </span></span>
<span><span class="co">##   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   3   2   2 </span></span>
<span><span class="co">##  81  82  83  84  85  86  87  88  89  90  91  92  93  94  95  96  97  98  99 100 </span></span>
<span><span class="co">##   2   2   2   2   2   2   3   2   2   2   2   2   2   2   2   2   2   2   2   2 </span></span>
<span><span class="co">## 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 </span></span>
<span><span class="co">##   3   2   3   3   3   3   2   3   3   3   3   3   3   2   3   3   3   3   3   2 </span></span>
<span><span class="co">## 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 </span></span>
<span><span class="co">##   3   2   3   2   3   3   2   3   3   3   3   3   3   2   2   3   3   3   2   3 </span></span>
<span><span class="co">## 141 142 143 144 145 146 147 148 149 150 </span></span>
<span><span class="co">##   3   3   2   3   3   3   3   3   3   3 </span></span>
<span><span class="co">## </span></span>
<span><span class="co">## $medoid</span></span>
<span><span class="co">## [1]   8  56 113</span></span>
<span><span class="co">## </span></span>
<span><span class="co">## $minimum_distance</span></span>
<span><span class="co">## [1] 45.44091</span></span></code></pre>
<p>Then, the classification table can be attained.</p>
<div class="sourceCode" id="cb120"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="op">(</span><span class="va">inckmtable</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/table.html" class="external-link">table</a></span><span class="op">(</span><span class="va">inckm</span><span class="op">$</span><span class="va">cluster</span>, <span class="va">iris</span><span class="op">[</span>,<span class="fl">5</span><span class="op">]</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">##    </span></span>
<span><span class="co">##     setosa versicolor virginica</span></span>
<span><span class="co">##   1     50          0         0</span></span>
<span><span class="co">##   2      0         46        11</span></span>
<span><span class="co">##   3      0          4        39</span></span></code></pre>
<p>The misclassification rate is</p>
<div class="sourceCode" id="cb122"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="op">(</span><span class="fl">9</span><span class="op">+</span><span class="fl">3</span><span class="op">)</span><span class="op">/</span><span class="fu"><a href="https://rdrr.io/r/base/sum.html" class="external-link">sum</a></span><span class="op">(</span><span class="va">inckmtable</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">## [1] 0.08</span></span></code></pre>
<p>The algorithm has <code>8</code>% misclassification rate such that
the <a href="#rkm">RKM</a> algorithm performs the best among the four
algorithms in the <code>iris</code> data set with the <code>mrw</code>
distance.</p>
<p><a href="#intro">(Back to Intoduction)</a></p>
</div>
<div class="section level4">
<h4 id="skm">3.E. Simple k-medoids algorithm (<code>skm</code>)<a class="anchor" aria-label="anchor" href="#skm"></a>
</h4>
<p>The simple k-medoid (SKM) algorithm has been proposed by <span class="citation">Budiaji and Leisch (2019)</span>. The <code>skm</code>
function runs this algorithm to cluster the objects. The compulsory
inputs are a distance matrix or distance object and a number of
clusters. Hence, the SKM algorithm for the <code>iris</code> data set
is</p>
<div class="sourceCode" id="cb124"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co">#run the sfkm algorihtm on iris data set with mrw distance</span></span>
<span><span class="op">(</span><span class="va">simplekm</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/skm.html">skm</a></span><span class="op">(</span><span class="va">mrwdist</span>, ncluster <span class="op">=</span> <span class="fl">3</span>, seeding <span class="op">=</span> <span class="fl">50</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">## $cluster</span></span>
<span><span class="co">##   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17  18  19  20 </span></span>
<span><span class="co">##   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1 </span></span>
<span><span class="co">##  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35  36  37  38  39  40 </span></span>
<span><span class="co">##   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1 </span></span>
<span><span class="co">##  41  42  43  44  45  46  47  48  49  50  51  52  53  54  55  56  57  58  59  60 </span></span>
<span><span class="co">##   1   1   1   1   1   1   1   1   1   1   2   3   2   3   3   3   3   3   3   3 </span></span>
<span><span class="co">##  61  62  63  64  65  66  67  68  69  70  71  72  73  74  75  76  77  78  79  80 </span></span>
<span><span class="co">##   3   3   3   3   3   3   3   3   3   3   3   3   3   3   3   3   3   2   3   3 </span></span>
<span><span class="co">##  81  82  83  84  85  86  87  88  89  90  91  92  93  94  95  96  97  98  99 100 </span></span>
<span><span class="co">##   3   3   3   3   3   3   2   3   3   3   3   3   3   3   3   3   3   3   3   3 </span></span>
<span><span class="co">## 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 </span></span>
<span><span class="co">##   2   3   2   2   2   2   3   2   2   2   2   2   2   3   2   2   2   2   2   3 </span></span>
<span><span class="co">## 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 </span></span>
<span><span class="co">##   2   3   2   3   2   2   3   2   2   2   2   2   2   3   3   2   2   2   3   2 </span></span>
<span><span class="co">## 141 142 143 144 145 146 147 148 149 150 </span></span>
<span><span class="co">##   2   2   3   2   2   2   2   2   2   2 </span></span>
<span><span class="co">## </span></span>
<span><span class="co">## $medoid</span></span>
<span><span class="co">## [1]   8 113  56</span></span>
<span><span class="co">## </span></span>
<span><span class="co">## $minimum_distance</span></span>
<span><span class="co">## [1] 45.44091</span></span></code></pre>
<p>Then, a classification table can be obtained.</p>
<div class="sourceCode" id="cb126"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="op">(</span><span class="va">simpletable</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/table.html" class="external-link">table</a></span><span class="op">(</span><span class="va">simplekm</span><span class="op">$</span><span class="va">cluster</span>, <span class="va">iris</span><span class="op">[</span>,<span class="fl">5</span><span class="op">]</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">##    </span></span>
<span><span class="co">##     setosa versicolor virginica</span></span>
<span><span class="co">##   1     50          0         0</span></span>
<span><span class="co">##   2      0          4        39</span></span>
<span><span class="co">##   3      0         46        11</span></span></code></pre>
<p>Applying the SKM algorithm in <code>iris</code> data set with the
Manhattan weighted by range, the misclassification rate is</p>
<div class="sourceCode" id="cb128"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="op">(</span><span class="fl">4</span><span class="op">+</span><span class="fl">11</span><span class="op">)</span><span class="op">/</span><span class="fu"><a href="https://rdrr.io/r/base/sum.html" class="external-link">sum</a></span><span class="op">(</span><span class="va">simpletable</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">## [1] 0.1</span></span></code></pre>
<p><a href="#intro">(Back to Intoduction)</a></p>
</div>
</div>
<div class="section level3">
<h3 id="cluster-validation">4. Cluster validation<a class="anchor" aria-label="anchor" href="#cluster-validation"></a>
</h3>
<p>The clustering algorithm result has to be validated. There are two
types of validation implemented in the <a href="https://cran.r-project.org/package=kmed" class="external-link"><strong>kmed</strong></a>
package. They are internal and relative criteria validations.</p>
<div class="section level4">
<h4 id="a--internal-criteria">4.A. Internal criteria<a class="anchor" aria-label="anchor" href="#a--internal-criteria"></a>
</h4>
</div>
<div class="section level4">
<h4 id="sil">4.A.1. Silhouette (<code>sil</code>)<a class="anchor" aria-label="anchor" href="#sil"></a>
</h4>
<p><span class="citation">Rousseeuw (1987)</span> has proposed a
silhouette index as an internal measure of validation. It is based on
the average distance of objects within a cluster and between the nearest
cluster. The <code>sil</code> function calculates the silhouette index
of clustering result. The arguments are a distance matrix or distance
object, id medoids, and cluster membership. It produce a list of
silhouette indices and sihouette plots.</p>
<p>The silhouette index and plot of the best clustering result of
<code>iris</code> data set via <a href="#rkm">RKM</a> is presented.</p>
<div class="sourceCode" id="cb130"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co">#calculate silhouette of the RKM result of iris data set </span></span>
<span><span class="va">siliris</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/sil.html">sil</a></span><span class="op">(</span><span class="va">mrwdist</span>, <span class="va">rkm</span><span class="op">$</span><span class="va">medoid</span>, <span class="va">rkm</span><span class="op">$</span><span class="va">cluster</span>, </span>
<span>                     title <span class="op">=</span> <span class="st">"Silhouette plot of Iris data set via RKM"</span><span class="op">)</span></span></code></pre></div>
<p>The silhouette index of each object can be obtained by</p>
<div class="sourceCode" id="cb131"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co">#silhouette indices of objects 49 to 52</span></span>
<span><span class="va">siliris</span><span class="op">$</span><span class="va">result</span><span class="op">[</span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">49</span><span class="op">:</span><span class="fl">52</span><span class="op">)</span>,<span class="op">]</span></span></code></pre></div>
<pre><code><span><span class="co">##    silhouette cluster</span></span>
<span><span class="co">## 49 0.49986165       2</span></span>
<span><span class="co">## 50 0.01977318       2</span></span>
<span><span class="co">## 51 0.59663837       3</span></span>
<span><span class="co">## 52 0.61488150       3</span></span></code></pre>
<p>Then, the plot is presented by</p>
<div class="sourceCode" id="cb133"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">siliris</span><span class="op">$</span><span class="va">plot</span></span></code></pre></div>
<p><img src="kmedoid_files/figure-html/unnamed-chunk-65-1.png" width="672"></p>
<p><a href="#intro">(Back to Intoduction)</a></p>
</div>
<div class="section level4">
<h4 id="csv">4.A.2. Centroid-based shadow value (<code>csv</code>)<a class="anchor" aria-label="anchor" href="#csv"></a>
</h4>
<p>An other way to measure internal validation with its corresponding
plot is by presenting the centroid-based shadow value <span class="citation">(Leisch 2010)</span>. The <code>csv</code> function
calculates and plots the centroid-base shadow value of each object,
which is based on the first and second closest medoids. The centroid of
the original version of the csv is replaced by medoids in the
<code>csv</code> function to adapt the k-medoids algorithm.</p>
<p>The required arguments in the <code>csv</code> function is identical
to the <a href="#sil">silhouette (<code>sil</code>)</a> function. Thus,
the shadow value and plot of the best clustering result of
<code>iris</code> data set via <a href="#rkm">RKM</a> can be obtained
by</p>
<div class="sourceCode" id="cb134"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co">#calculate centroid-base shadow value of the RKM result of iris data set </span></span>
<span><span class="va">csviris</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/csv.html">csv</a></span><span class="op">(</span><span class="va">mrwdist</span>, <span class="va">rkm</span><span class="op">$</span><span class="va">medoid</span>, <span class="va">rkm</span><span class="op">$</span><span class="va">cluster</span>, </span>
<span>                     title <span class="op">=</span> <span class="st">"CSV plot of Iris data set via RKM"</span><span class="op">)</span></span></code></pre></div>
<p>The centroid-based shadow values of objects 49 to 52, for instance,
are presented by</p>
<div class="sourceCode" id="cb135"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co">#shadow values of objects 49 to 52</span></span>
<span><span class="va">csviris</span><span class="op">$</span><span class="va">result</span><span class="op">[</span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">49</span><span class="op">:</span><span class="fl">52</span><span class="op">)</span>,<span class="op">]</span></span></code></pre></div>
<pre><code><span><span class="co">##          csv cluster</span></span>
<span><span class="co">## 49 0.7899687       2</span></span>
<span><span class="co">## 50 0.0000000       2</span></span>
<span><span class="co">## 51 0.3604380       3</span></span>
<span><span class="co">## 52 0.2473829       3</span></span></code></pre>
<p>The centroid-based shadow value plot is also produced.</p>
<div class="sourceCode" id="cb137"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">csviris</span><span class="op">$</span><span class="va">plot</span></span></code></pre></div>
<p><img src="kmedoid_files/figure-html/unnamed-chunk-68-1.png" width="672"></p>
<p><a href="#intro">(Back to Intoduction)</a></p>
</div>
<div class="section level4">
<h4 id="msv">4.A.3. Medoid-based shadow value (<code>msv</code>)<a class="anchor" aria-label="anchor" href="#msv"></a>
</h4>
<p>An other way to measure internal validation by combining silhoutte
and csv properties is by a medoid-based shadow value (msv) <span class="citation">(Budiaji 2019)</span>. The <code>msv</code> function
calculates and plots the medoid-based shadow value of each object, which
is based on the first and second closest medoids.</p>
<p>The required arguments in the <code>msv</code> function is identical
to the <a href="#csv">centroid-based shadow value (<code>csv</code>)</a>
function. Thus, the medoid-based shadow value and plot of the best
clustering result of <code>iris</code> data set via <a href="#rkm">RKM</a> can be obtained by</p>
<div class="sourceCode" id="cb138"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co">#calculate medoid-based shadow value of the RKM result of iris data set </span></span>
<span><span class="va">msviris</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/msv.html">msv</a></span><span class="op">(</span><span class="va">mrwdist</span>, <span class="va">rkm</span><span class="op">$</span><span class="va">medoid</span>, <span class="va">rkm</span><span class="op">$</span><span class="va">cluster</span>, </span>
<span>                     title <span class="op">=</span> <span class="st">"MSV plot of Iris data set via RKM"</span><span class="op">)</span></span></code></pre></div>
<p>The medoid-based shadow values of objects 49 to 52, for instance, are
presented by</p>
<div class="sourceCode" id="cb139"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co">#Medoid-based shadow values of objects 49 to 52</span></span>
<span><span class="va">msviris</span><span class="op">$</span><span class="va">result</span><span class="op">[</span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">49</span><span class="op">:</span><span class="fl">52</span><span class="op">)</span>,<span class="op">]</span></span></code></pre></div>
<pre><code><span><span class="co">##          msv cluster</span></span>
<span><span class="co">## 49 0.3471503       2</span></span>
<span><span class="co">## 50 1.0000000       2</span></span>
<span><span class="co">## 51 0.7801620       3</span></span>
<span><span class="co">## 52 0.8588494       3</span></span></code></pre>
<p>The shadow value plot is also produced.</p>
<div class="sourceCode" id="cb141"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">msviris</span><span class="op">$</span><span class="va">plot</span></span></code></pre></div>
<p><img src="kmedoid_files/figure-html/unnamed-chunk-71-1.png" width="672"></p>
<p><a href="#intro">(Back to Intoduction)</a></p>
</div>
<div class="section level4">
<h4 id="boot">4.B. Relative criteria<a class="anchor" aria-label="anchor" href="#boot"></a>
</h4>
<p>The relative criteria evaluate a clustering algorithm result by
applying re-sampling strategy. Thus, a bootstrap strategy can be
applied. It is expected that the result of the cluster bootstraping is
robust over all replications <span class="citation">(Dolnicar and Leisch
2010)</span>. There are three steps to validate the cluster result via
the boostraping strategy.</p>
<div class="section level5">
<h5 id="stp1">Step 1 Creating a matrix of bootstrap replicates<a class="anchor" aria-label="anchor" href="#stp1"></a>
</h5>
<p>To create a matrix of bootstrap replicates, the
<code>clustboot</code> function can be applied. There are five arguments
in the <code>clustboot</code> function with the <code>algorithm</code>
argument being the most important. The <code>algorithm</code> argument
is the argument for a clustering algorithm that a user wants to
evaluate. It has to be a <em>function</em>. When the <a href="#rkm">RKM</a> of <code>iris</code> data set is validated, for
instance, the RKM function, which is required as an input in the
<code>algorithm</code> argument, is</p>
<div class="sourceCode" id="cb142"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co">#The RKM function for an argument input</span></span>
<span><span class="va">rkmfunc</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">x</span>, <span class="va">nclust</span><span class="op">)</span> <span class="op">{</span></span>
<span>  <span class="va">res</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/rankkmed.html">rankkmed</a></span><span class="op">(</span><span class="va">x</span>, <span class="va">nclust</span>, m <span class="op">=</span> <span class="fl">10</span>, iterate <span class="op">=</span> <span class="fl">50</span><span class="op">)</span></span>
<span>  <span class="kw"><a href="https://rdrr.io/r/base/function.html" class="external-link">return</a></span><span class="op">(</span><span class="va">res</span><span class="op">$</span><span class="va">cluster</span><span class="op">)</span></span>
<span><span class="op">}</span></span></code></pre></div>
<p>When a function is created, it has to have two input arguments. They
are <code>x</code> (a distance matrix) and <code>nclust</code> (a number
of clusters). The output, on the other hand, is <em>a vector</em> of
cluster membership (<code>res$cluster</code>). Thus, the matrix of
bootstrap replicates can be produced by</p>
<div class="sourceCode" id="cb143"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co">#The RKM algorthim evaluation by inputing the rkmfunc function</span></span>
<span><span class="co">#in the algorithm argument</span></span>
<span><span class="va">rkmbootstrap</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/clustboot.html">clustboot</a></span><span class="op">(</span><span class="va">mrwdist</span>, nclust<span class="op">=</span><span class="fl">3</span>, nboot<span class="op">=</span><span class="fl">50</span>, algorithm <span class="op">=</span> <span class="va">rkmfunc</span><span class="op">)</span></span></code></pre></div>
<p>with the objects 1 to 4 on the first to fifth replications being</p>
<div class="sourceCode" id="cb144"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">rkmbootstrap</span><span class="op">[</span><span class="fl">1</span><span class="op">:</span><span class="fl">4</span>,<span class="fl">1</span><span class="op">:</span><span class="fl">5</span><span class="op">]</span></span></code></pre></div>
<pre><code><span><span class="co">##      [,1] [,2] [,3] [,4] [,5]</span></span>
<span><span class="co">## [1,]    1    1    1    0    1</span></span>
<span><span class="co">## [2,]    1    1    1    1    0</span></span>
<span><span class="co">## [3,]    0    1    0    1    0</span></span>
<span><span class="co">## [4,]    0    1    0    0    2</span></span></code></pre>
<p>The <code>rkmbootstrap</code> is a matrix of bootrstrap replicates
with a dimension of <em>150 x 50</em>, i.e. <em>n x b</em>, where
<em>n</em> is the number of objects and <em>b</em> is the number of
bootstrap replicates. <strong>Note</strong> that the default evaluated
algorithm is the <a href="#sfkm">SFKM</a> algorithm such that if a user
ignores the <code>algorithm</code> argument, the matrix of bootstrap
replicates can still be produced. However, it misleads because it does
not evaluate the user’s own algorithm.</p>
</div>
<div class="section level5">
<h5 id="stp2">Step 2 Transforming the bootstrap matrix into a consensus
matrix<a class="anchor" aria-label="anchor" href="#stp2"></a>
</h5>
<p>The matrix of bootstrap replicates produced by the
<code>clustboot</code> in the <a href="#stp1">step 1</a> can be
transformed into a consensus matrix with a dimension of <em>n x n</em>
via the <code>consensusmatrix</code> function. An element of the
consensus matrix in row <em>i</em> dan column <em>j</em> is an agreement
value between objects <em>i</em> and <em>j</em> to be in the same
cluster when they are taken as a sample at the same time <span class="citation">(Monti et al. 2003)</span>.</p>
<p>However, it requires an algorithm to order the objects in such a way
that objects in the same cluster are close to each other. The
<code>consensusmatrix</code> function has the <code>reorder</code>
argument to comply this task. It is similar to the
<code>algorithm</code> argument in the <code>clustboot</code> function
in the <a href="#stp1">step 1</a> where the <code>reorder</code> has to
be a function that has two arguments and a vector of output.</p>
<p>Transforming the <code>rkmbootstrap</code> into a consensus matrix
via the ward linkage algorithm to oder the objects, for example, can
obtained by</p>
<div class="sourceCode" id="cb146"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co">#The ward function to order the objects in the consensus matrix</span></span>
<span><span class="va">wardorder</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">x</span>, <span class="va">nclust</span><span class="op">)</span> <span class="op">{</span></span>
<span>  <span class="va">res</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/hclust.html" class="external-link">hclust</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/dist.html" class="external-link">as.dist</a></span><span class="op">(</span><span class="va">x</span><span class="op">)</span>, method <span class="op">=</span> <span class="st">"ward.D2"</span><span class="op">)</span></span>
<span>  <span class="va">member</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/cutree.html" class="external-link">cutree</a></span><span class="op">(</span><span class="va">res</span>, <span class="va">nclust</span><span class="op">)</span></span>
<span>  <span class="kw"><a href="https://rdrr.io/r/base/function.html" class="external-link">return</a></span><span class="op">(</span><span class="va">member</span><span class="op">)</span></span>
<span><span class="op">}</span></span>
<span><span class="va">consensusrkm</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/consensusmatrix.html">consensusmatrix</a></span><span class="op">(</span><span class="va">rkmbootstrap</span>, nclust <span class="op">=</span> <span class="fl">3</span>, <span class="va">wardorder</span><span class="op">)</span></span></code></pre></div>
<p>The first to fourth rows and columns can be displayed as</p>
<div class="sourceCode" id="cb147"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">consensusrkm</span><span class="op">[</span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="fl">4</span><span class="op">)</span>,<span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="fl">4</span><span class="op">)</span><span class="op">]</span></span></code></pre></div>
<pre><code><span><span class="co">##           1         1         1         1</span></span>
<span><span class="co">## 1 1.0000000 0.8823529 0.7333333 0.8421053</span></span>
<span><span class="co">## 1 0.8823529 1.0000000 1.0000000 0.9444444</span></span>
<span><span class="co">## 1 0.7333333 1.0000000 1.0000000 0.9473684</span></span>
<span><span class="co">## 1 0.8421053 0.9444444 0.9473684 1.0000000</span></span></code></pre>
</div>
<div class="section level5">
<h5 id="step-3-visualizing-the-consensus-matrix-in-a-heatmap">Step 3 Visualizing the consensus matrix in a heatmap<a class="anchor" aria-label="anchor" href="#step-3-visualizing-the-consensus-matrix-in-a-heatmap"></a>
</h5>
<p>The ordered consensus matrix in the <a href="#stp2">step 2</a> can be
visualized in a heatmap applying the <code>clustheatmap</code> function.
The agreement indices in the consensus matrix can be transformed via a
non-linear transformation <span class="citation">(Hahsler and Hornik
2011)</span>. Thus, the <code>consensusrkm</code> can visualize into</p>
<div class="sourceCode" id="cb149"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/clustheatmap.html">clustheatmap</a></span><span class="op">(</span><span class="va">consensusrkm</span>, <span class="st">"Iris data evaluated by the RKM, ordered by Ward linkage"</span><span class="op">)</span></span></code></pre></div>
<p><img src="kmedoid_files/figure-html/unnamed-chunk-77-1.png" width="672"></p>
<p><a href="#intro">(Back to Intoduction)</a></p>
</div>
</div>
</div>
<div class="section level3">
<h3 id="cluster-visualization">5. Cluster visualization<a class="anchor" aria-label="anchor" href="#cluster-visualization"></a>
</h3>
<p>A cluster visualization of the clustering result can enhance the data
structure understanding. The biplot and marked barplot are presented to
visualize the clustering result.</p>
<div class="section level4">
<h4 id="biplot">A. Biplot<a class="anchor" aria-label="anchor" href="#biplot"></a>
</h4>
<p>The <code>pcabiplot</code> function can be applied to plot a
clustering result from a numerical data set. The numerical data set has
to be converted into a principle component object via the
<code>prcomp</code> function. The <code>x</code> and <code>y</code> axes
in the plot can be replaced by any component of the principle
components. The colour of the objects can be adjusted based on the
cluster membership by supplying a vector of membership in the
<code>colobj</code> argument.</p>
<p>The <code>iris</code> data set can be plotted in a pca biplot with
the colour objects based on the <a href="#rkm">RKM</a> algorithm
result.</p>
<div class="sourceCode" id="cb150"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co">#convert the data set into principle component object</span></span>
<span><span class="va">pcadat</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/prcomp.html" class="external-link">prcomp</a></span><span class="op">(</span><span class="va">iris</span><span class="op">[</span>,<span class="fl">1</span><span class="op">:</span><span class="fl">4</span><span class="op">]</span>, scale. <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span>
<span><span class="co">#plot the pca with the corresponding RKM clustering result </span></span>
<span><span class="fu"><a href="../reference/pcabiplot.html">pcabiplot</a></span><span class="op">(</span><span class="va">pcadat</span>, colobj <span class="op">=</span> <span class="va">rkm</span><span class="op">$</span><span class="va">cluster</span>, o.size <span class="op">=</span> <span class="fl">2</span><span class="op">)</span></span></code></pre></div>
<p><img src="kmedoid_files/figure-html/unnamed-chunk-78-1.png" width="672"></p>
<p>The second principle component can be replaced by the third principle
component.</p>
<div class="sourceCode" id="cb151"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/pcabiplot.html">pcabiplot</a></span><span class="op">(</span><span class="va">pcadat</span>, y <span class="op">=</span> <span class="st">"PC3"</span>,colobj <span class="op">=</span> <span class="va">rkm</span><span class="op">$</span><span class="va">cluster</span>, o.size <span class="op">=</span> <span class="fl">1.5</span><span class="op">)</span></span></code></pre></div>
<p><img src="kmedoid_files/figure-html/unnamed-chunk-79-1.png" width="672"></p>
<p><a href="#intro">(Back to Intoduction)</a></p>
</div>
<div class="section level4">
<h4 id="barplotnum">B. Marked barplot<a class="anchor" aria-label="anchor" href="#barplotnum"></a>
</h4>
<p>A marked barplot has been proposed by <span class="citation">Dolnicar
and Leisch (2014)</span>; <span class="citation">Leisch (2008)</span>
where the mark indicates a significant difference between the cluster’s
mean and population’s mean in each variable. The <code>barplot</code>
function creates a barplot of each cluster with a particular significant
level. The layout of the barplot is set in the <code>nc</code>
argument.</p>
<p>The barplot of <code>iris</code> data set partitioned by the <a href="#rkm">RKM</a> algorithm is</p>
<div class="sourceCode" id="cb152"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/barplotnum.html">barplotnum</a></span><span class="op">(</span><span class="va">iris</span><span class="op">[</span>,<span class="fl">1</span><span class="op">:</span><span class="fl">4</span><span class="op">]</span>, <span class="va">rkm</span><span class="op">$</span><span class="va">cluster</span>, alpha <span class="op">=</span> <span class="fl">0.05</span><span class="op">)</span></span></code></pre></div>
<p><img src="kmedoid_files/figure-html/unnamed-chunk-80-1.png" width="672"></p>
<p>while the layout is changed into 2 columns and the alpha is set into
1%, it becomes</p>
<div class="sourceCode" id="cb153"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/barplotnum.html">barplotnum</a></span><span class="op">(</span><span class="va">iris</span><span class="op">[</span>,<span class="fl">1</span><span class="op">:</span><span class="fl">4</span><span class="op">]</span>, <span class="va">rkm</span><span class="op">$</span><span class="va">cluster</span>, nc <span class="op">=</span> <span class="fl">2</span>, alpha <span class="op">=</span> <span class="fl">0.01</span><span class="op">)</span></span></code></pre></div>
<p><img src="kmedoid_files/figure-html/unnamed-chunk-81-1.png" width="672"></p>
<p><a href="#intro">(Back to Intoduction)</a></p>
<hr>
</div>
</div>
<div class="section level2">
<h2 class="unnumbered" id="ref">References<a class="anchor" aria-label="anchor" href="#ref"></a>
</h2>
<div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-ahmad" class="csl-entry">
Ahmad, A., and L. Dey. 2007. <span>“A K-Mean Clustering Algorithm for
Mixed Numeric and Categorical Data.”</span> <em>Data and Knowledge
Engineering</em> 63 (November): 503–27. <a href="https://doi.org/10.1016/j.datak.2007.03.016" class="external-link">https://doi.org/10.1016/j.datak.2007.03.016</a>.
</div>
<div id="ref-budiaji2" class="csl-entry">
Budiaji, W. 2019. <span>“Medoid-Based Shadow Value Validation and
Visualization.”</span> <em>International Journal of Advances in
Intelligent Informatics</em> 5 (July): 76–88. <a href="https://doi.org/10.26555/ijain.v5i2.326" class="external-link">https://doi.org/10.26555/ijain.v5i2.326</a>.
</div>
<div id="ref-budiaji1" class="csl-entry">
Budiaji, W., and F. Leisch. 2019. <span>“Simple K-Medoids Partitioning
Algorithm for Mixed Variable Data.”</span> <em>Algorithms</em> 12
(August): 177. <a href="https://doi.org/10.3390/a12090177" class="external-link">https://doi.org/10.3390/a12090177</a>.
</div>
<div id="ref-dolnicar" class="csl-entry">
Dolnicar, S., and F. Leisch. 2010. <span>“Evaluation of Structure and
Reproducibility of Cluster Solutions Using the Bootstrap.”</span>
<em>Marketing Letters</em> 21 (March): 83–101.
</div>
<div id="ref-dolnicar2" class="csl-entry">
———. 2014. <span>“Using Graphical Statistics to Better Understand Market
Segmentation Solutions.”</span> <em>International Journal of Market
Research</em> 56 (March): 207–30.
</div>
<div id="ref-gower" class="csl-entry">
Gower, J. 1971. <span>“A General Coefficient of Similarity and Some of
Its Properties.”</span> <em>Biometrics</em> 27 (December): 857–71.
</div>
<div id="ref-hahsler" class="csl-entry">
Hahsler, M., and K. Hornik. 2011. <span>“Consensus Clustering;
Dissimilarity Plots; A Visual Exploration Tool for Partitional
Clustering.”</span> <em>Journal of Computational and Graphical
Statistics</em> 20 (August): 335–54. <a href="https://doi.org/10.1198/jcgs.2010.09139" class="external-link">https://doi.org/10.1198/jcgs.2010.09139</a>.
</div>
<div id="ref-harikumar" class="csl-entry">
Harikumar, S., and S. PV. 2015. <span>“K-Medoid Clustering for
Heterogeneous Data Sets.”</span> <em>JProcedia Computer Science</em> 70:
226–37. <a href="https://doi.org/10.1016/j.procs.2015.10.077" class="external-link">https://doi.org/10.1016/j.procs.2015.10.077</a>.
</div>
<div id="ref-huang" class="csl-entry">
Huang, Z. 1997. <span>“Clustering Large Data Sets with Mixed Numeric and
Categorical Values.”</span> In <em>The First Pacific-Asia Conference on
Knowledge Discovery and Data Mining</em>, 21–34.
</div>
<div id="ref-leisch2" class="csl-entry">
Leisch, F. 2008. <span>“Visualizing Cluster Analysis and Finite Mixture
Models.”</span> In <em>Handbook of Data Visualization</em>, 561–87.
Springer Verlag.
</div>
<div id="ref-leisch" class="csl-entry">
———. 2010. <span>“Neighborhood Graphs, Stripes and Shadow Plots for
Cluster Visualization.”</span> <em>Statistics and Computing</em> 20
(October): 457–69.
</div>
<div id="ref-monti" class="csl-entry">
Monti, S., P. Tamayo, J. Mesirov, and T. Golub. 2003. <span>“Consensus
Clustering; A Resampling-Based Method for Class Discovery and
Visualization of Gene Expression Microarray Data.”</span> <em>Machine
Learning</em> 52 (July): 91–118.
</div>
<div id="ref-park" class="csl-entry">
Park, H., and C. Jun. 2009. <span>“A Simple and Fast Algorithm for
K-Medoids Clustering.”</span> <em>Expert Systems with Applications</em>
36 (2): 3336–41. <a href="https://doi.org/10.1016/j.eswa.2008.01.039" class="external-link">https://doi.org/10.1016/j.eswa.2008.01.039</a>.
</div>
<div id="ref-podani" class="csl-entry">
Podani, J. 1999. <span>“Extending Gower’s General Coefficient of
Similarity to Ordinal Characters.”</span> <em>Taxon</em> 48 (May):
331–40.
</div>
<div id="ref-reynolds" class="csl-entry">
Reynolds, A. P., G. Richards, B. De La Iglesia, and V. J. Rayward-Smith.
2006. <span>“Clustering Rules; A Comparison of Partitioning and
Hierarchical Clustering Algorithms.”</span> <em>Journal of Mathematical
Modelling and Algorithms</em> 5 (March): 475–504.
</div>
<div id="ref-rousseeuw" class="csl-entry">
Rousseeuw, P. J. 1987. <span>“A Graphical Aid to the Interpretation and
Validation of Cluster Analysis.”</span> <em>Journal of Computational and
Applied Mathematics</em> 20 (November): 53–65. <a href="https://doi.org/10.1016/0377-0427(87)90125-7" class="external-link">https://doi.org/10.1016/0377-0427(87)90125-7</a>.
</div>
<div id="ref-wishart" class="csl-entry">
Wishart, D. 2003. <span>“K-Means Clustering with Outlier Detection,
Mixed Variables and Missing Values.”</span> In <em>Exploratory Data
Analysis in Empirical Research; Proceedings of the 25th Annual
Conference of the Gesellschaft Fur Klassifikation e.v., University of
Munich, March 14-16, 2001</em>, 27:216–26. Springer Berlin Heidelberg.
</div>
<div id="ref-yu" class="csl-entry">
Yu, D., G. Liu, M. Guo, and X. Liu. 2018. <span>“An Improved K-Medoids
Algorithm Based on Step Increasing and Optimizing Medoids.”</span>
<em>Expert Systems with Applications</em> 92 (February): 464–73. <a href="https://doi.org/10.1016/j.eswa.2017.09.052" class="external-link">https://doi.org/10.1016/j.eswa.2017.09.052</a>.
</div>
<div id="ref-zadegan" class="csl-entry">
Zadegan, S.M.R, M. Mirzaie, and F. Sadoughi. 2013. <span>“Ranked
k-Medoids A Fast and Accurate Rank-Based Partitioning Algorithm for
Clustering Large Datasets.”</span> <em>Knowledge-Based Systems</em> 39
(February): 133–43. <a href="https://doi.org/10.1016/j.knosys.2012.10.012" class="external-link">https://doi.org/10.1016/j.knosys.2012.10.012</a>.
</div>
</div>
</div>
  </main><aside class="col-md-3"><nav id="toc"><h2>On this page</h2>
    </nav></aside>
</div>



    <footer><div class="pkgdown-footer-left">
  <p></p>
<p>NULL Provided without <strong>any warranty</strong>.</p>
</div>

<div class="pkgdown-footer-right">
  <p></p>
<p>NULL</p>
</div>

    </footer>
</div>

  

  

  </body>
</html>
